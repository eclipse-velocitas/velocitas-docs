[{"body":"Introduction The Velocitas development model is centered around what are known as Vehicle Apps. Automation allows engineers to make high-impact changes frequently and deploy Vehicle Apps through cloud backends as over-the-air updates. The Vehicle App development model is about speed and agility paired with state-of-the-art software quality.\nDevelopment Architecture Velocitas provides a flexible development architecture for Vehicle Apps. The following diagram shows the major components of the Velocitas stack.\nOverview of the progamming model   Vehicle Apps The Vehicle Applications (aka. Vehicle Apps) contain the business logic that needs to be executed on a vehicle. A Vehicle App is implemented on top of a Vehicle Model and its underlying language-specific SDK. Many concepts of cloud-native and twelve-factor applications apply to Vehicle Apps as well and are summarized in the next chapter.\nVehicle Models A Vehicle Model makes it possible to easily get vehicle data from the Vehicle Data Broker and to execute remote procedure calls over gRPC against Vehicle Services and other Vehicle Apps. It is generated from the underlying semantic models for a concrete programming language as a graph-based, strongly-typed, intellisense-enabled library. The elements of the vehicle models are defined in the SDKs.\nSDKs To reduce the effort required to implement Vehicle Apps, Velocitas provides a set of SDKs for different programming languages. A first SDK is available for Python, further SDKs for Rust and C/C++ are planned. Next to a Vehicle Apps abstraction, the SDKs are Middleware-enabled, provide connectivity to the Vehicle Data Broker and contain the ontology in the form of base classes to create Vehicle Models.\nVehicle Services Vehicle Services provide service interfaces to control actuators or to trigger (complex) actions. E.g. they communicate with the vehicle internals networks like CAN or Ethernet, which are connected to actuators, electronic control units (ECUs) and other vehicle computers (VCs). They may provide a simulation mode to run without a network interface. Vehicle services may feed data to the Vehicle Data Broker and may expose gRPC endpoints, which can be invoked by Vehicle Apps over a Vehicle Model\nVehicle Data Broker Vehicle data is stored in the Vehicle Data Broker conforming to an underlying Semantic Model like VSS. Vehicle Apps can either pull this data or subscribe for updates. In addition, it supports rule-based access to reduce the number of updates sent. The storage of the vehicle data broker will be the vehicle twin that syncs its data to the cloud.\nSemantic models The Vehicle Signal Specification (VSS) provides a domain taxonomy for vehicle signals and defines the vehicle data semantically, which is exchanged between Vehicle Apps and the vehicle data broker.\nThe Vehicle Service Catalog (VSC) extends VSS with functional remote procedure call definitions and semantically defines the gRPC interfaces of Vehicle Services and Vehicle Apps.\nAs an alternative to VSS and VSC, vehicle data and services can be defined semantically in a general IoT modelling language like Digital Twin Definition Language (DTDL) or BAMM Aspect Meta Model BAMM as well.\nCommunication Protocols Asynchronous communication between Vehicle Apps and other vehicle components as well as cloud connectivity is facilitated through MQTT messaging. Direct, synchronous communication between Vehicle Apps, Vehicle Services and the Vehicle Data Broker is based on the gRPC protocol.\nMiddleware Velocitas leverages dapr for gRPC service discovery, Open Telemetry tracing and the publish/subscribe building block as a higher-level abstraction over MQTT messaging.\nVehicle Edge Operating System Vehicle Apps are expected to run on a Linux-based operating system. An OCI-compliant container runtime is required to host the Vehicle App containers and the dapr middleware mandates a Kubernetes control plane. For publish/subscribe messaging a MQTT broker must be available (e.g., Eclipse Mosquitto).\nVehicle App characteristics Code Base Every Vehicle App is stored in its own repository. Tracked with version control, it can be deployed to multiple environments.\nPolyglot Vehicle Apps can be written in any programming language. System-level programming languages like Rust and C/C++ are particularly relevant for limited hardware resources found in vehicles, but higher-level languages like Python and JavaScript are also considered for special use cases.\nOCI-compliant containers Vehicle Apps are deployed as OCI-compliant containers. The size of these containers should be minimal to fit on constrained devices.\nIsolation Each Vehicle App should execute in its own process and should be self-contained with its interfaces and functionality exposed on its own port.\nConfigurations Configuration information is moved out of the Vehicle App, so that the same deployment can propagate across environments with the correct configuration applied.\nDisposability Favor fast startup and support graceful shutdowns to leave the system in a correct state.\nObservability Vehicle Apps provide traces, metrics and logs of every part of the application using Open Telemetry.\nOver-the-air updatability Vehicle Apps are released to cloud backends like the Bosch Mobility Cloud and can be updated in vehicles frequently over the air.\nDevelopment Process The starting point for developing Vehicle Apps is a Semantic Model of the vehicle data and vehicle services. Based on the Semantic Model, language-specific Vehicle Models are generated. Vehicle Models are then distributed as packages to the respective package manager of the chosen programming language (e.g. pip, cargo, npm, …).\nArchitectural diagram of the build process   After a Vehicle Model is available for the chosen programming language, the Vehicle App can be developed using the generated Vehicle Model and its core SDK.\nNext steps Vehicle Apps SDK Documentation  Python SDK Overview Coming soon: Rust SDK Overview  Working with Vehicle Models  Walkthrough: Creating a Python Vehicle Model Coming soon: Creating a Rust Vehicle Model  Working with Vehicle Apps  Walkthrough: Creating a Python Vehicle App Coming soon: Creating a Rust Vehicle App  ","categories":"","description":"Learn more about provided development model for Vehicle Apps.\n","excerpt":"Learn more about provided development model for Vehicle Apps.\n","ref":"/velocitas-docs/docs/concepts/development_model/","tags":"","title":"Development Model"},{"body":"The following information describes how to setup and configure the Development Container (DevContainer), and how to build, customize and test the sample Vehicle App, which is included in this repository. You will learn how to use the Vehicle App SDK, how to interact with the vehicle API and how to do CI/CD using the pre-configured GitHub workflows that come with the repository.\nOnce you have completed all steps, you will have a solid understanding of the Development Workflow and you will be able to reuse the Template Repository for your own Vehicle App develpment project.\nVehicle App Development with Visual Studio Code The Visual Studio Code Development Containers makes it possible to package a complete Vehicle App development environment, including Visual Studio Code extensions, Vehicle App SDK, Vehicle App runtime and all other development \u0026 testing tools into a container that is then started within your Visual Studio Code session.\nTo be able to use the DevContainer, you have to make sure that you fulfill the following prerequisites:\nSystem prerequisites  Install Docker Engine / Docker Desktop Install Visual Studio Code Add Remote-Containers extension via the marketplace or using the command line code --install-extension ms-vscode-remote.remote-containers   Proxy Configuration A non proxy configuration is used by default. If you are working behind a corporate proxy you will need to specify proxy settings.\n Please expand for information on configuring proxy settings A template configuration using proxies exists in .devcontainer/Dockerfile.Proxy and by setting the environment variable DEVCONTAINER_PROXY to .Proxy the file .devcontainer/Dockerfile.Proxy will be used instead of .devcontainer/Dockerfile.\nThe template configuration uses the following default configuration:\nENV HTTP_PROXY=\"http://172.17.0.1:${PROXY_PORT:-3128}\"  If your proxy is not available on 172.17.0.1 then you must modify .devcontainer/Dockerfile.Proxy. If your proxy does not use 3128 as port you can set another port in the environment variable DEVCONTAINER_PROXY_PORT  Windows:  Edit environment variables for your account Create an environment variable with name the DEVCONTAINER_PROXY and with the value .Proxy for your account  Don’t forget (dot) in value of the environment variable   If you are using a different Port than 3128 for your Proxy, you have to set another environment variable as follows:  DEVCONTAINER_PROXY_PORT=   Restart Visual Studio Code to pick up the new environment variable  macOS \u0026 Linux: echo \"export DEVCONTAINER_PROXY=.Proxy\" \u003e\u003e ~/.bash_profile source ~/.bash_profile Proxy Troubleshooting If you experience issues during initial DevContainer build and you want to start over, then you want to make sure you clean all images and volumes in Docker Desktop, otherwise cache might be used. Use the Docker Desktop UI to remove all volumes and containers.\nProxy settings in ~/.docker/config.json will override settings in .devcontainer/Dockerfile.Proxy, which can cause problems. In case the DevContainer is still not working, check if proxy settings are set correctly in the Docker user profile (~/.docker/config.json), see Docker Documentation for more details. Verify that the noProxy setting in ~/.docker/config.json (if existing) is compatible with the setting of NO_PROXY in .devcontainer/Dockerfile.Proxy. The development environment relies on communication to localhost (e.g. localhost, 127.0.0.1) and it is important that the proxy setting is correct so that connections to localhost are not forwarded to the proxy.\n Use Template Repository Create your own repository copy from the Template Repository by clicking the green button Use this template. You don’t have to include all branches.\nThe name MyOrg/MyFirstVehicleApp is used as a reference during the rest of document.\nFor more information on Template Repositories take a look at this GitHub Tutorial\nIn the following you will learn different possibilities to work with the repo. Basically you can work on your own machine using just Visual Studio Code or you can set up the environment on a remote agent, using GitHub Codespaces.\nVisual Studio Code With following steps you will clone and set up your development environment on your own machine using just Visual Studio Code.\n Start Visual Studio Code Press F1 and run the command Remote-Containers: Clone Repository within Container Volume... Select Clone a repository from GitHub in a Container Volume and choose the repository / branch to clone Enter the GitHub organization and repository name (e.g. MyOrg/MyFirstVehicleApp) and select the repository from the list Select the branch to clone from the list  The first time initializing the container will take a few minutes to build the image and to provision the tools inside the container.\n When opening the DevContainer for the first time, the following steps are necessary:\n  A manual reload of the dapr extension is required, if the extension hasn´t been installed before (Note: the reload button appears next to Dapr extension in extension menue).   Please expand for information on troubleshooting  If Visual Studio Code fails to directly clone your repository you can also use a workaround:\n clone the repo locally using your favorite Git tooling Start Visual Studio Code select Open Folder from the File menu open the root of the cloned repo a popup appears on the lower left side of Visual Studio Code click on Reopen in Container wait for the container to be set up  If the popup does not appear, you can also hit F1 and run the command Remote-Containers: Open Folder in Container\n  If the development container fails to build successfully (e.g. due to network issues), then wait for the current build to finish, press F1 and run the command Remote-Containers: Rebuild Container Without Cache\n The devContainer is using the docker-in-docker-feature to run docker containers within the container. Currently, this feature has the limitation that only one instance of a devContainer with the feature enabled can be running at the same time.\n Codespaces Another possibility to use your newly created repository is via GitHub Codespaces. You can either try it out directly in the browser or also use it inside Visual Studio Code. The main thing to remember is that everything is executed on a remote agent and the browser or Visual Studio Code just act as frontends.\nTo get started with Codespaces, you just have to follow a few steps:\n go to the webpage of your repository on GitHub (e.g. https://github.com/MyOrg/MyFirstVehicleApp) click on the green Code-button and select Codespaces on the top configure your Codespace if needed (defaults to the main branch and a standard agent) click on create  A new window will open where you see the logs for setting up the container. On this window you could now also choose to work with Visual Studio Code. The environment remains on a remote agent and Visual Studio Code establishes a connection to this machine.\nOnce everything is set up in the Codespace, you can work with it in the same way as with the normal DevContainer inside Visual Studio Code.\nStarting runtime services The runtime services (like Vehicle Data Broker or Vehicle Services) are required to develop vehicle apps and run integration tests.\nA Visual Studio Code task called Start Vehicle App runtime is available to run these in the correct order. Click F1, select command Tasks: Run Task, select Start VehicleApp runtime and Continue without scanning the output.\nYou should see the tasks run-mosquitto, run-vehicledatabroker, run-seatservice and run-feedercan being executed in the Visual Studio Code output panel.\nMore information about the tasks are available here.\nStart and test Vehicle App Now that your DevContainer is up and running, it is time to take a look at what’s inside:\n Vehicle App - This sample app is a basic blueprint and illustrates how to interact with the VAL Services and the Vehicle App SDK. Mosquitto MQTT Broker - The broker allows for interaction with other Vehicle Apps or the cloud and is used by the Vehicle App. The MQTT broker is running inside a docker image which is started automatically after starting the DevContainer.  Start and check Vehicle App Let’s start the sample Vehicle App to verify that you receive actual data from the API.\nOpen a new terminal and start the Vehicle App with the following command:\ndapr run --app-id seatadjuster --app-protocol grpc --app-port 50008 --config ./.dapr/config.yaml --components-path ./.dapr/components python3 ./src/SeatAdjusterApp/seatadjuster.py Once the Vehicle App is started, you can expect to receive the Current Position of the Vehicle Seat, which should be reported as 420.\nYou will see messages such as\n== APP == 04/06/2022 07:31:58 AM - __main__ - INFO - Current Position of the Vehicle Seat is: {'position': 420} To stop the Vehicle App instance: close the terminal window by hitting Ctrl + C.\nDebug Vehicle App After VAL Services and Vehicle App are running successfully, let’s start a debug session for the Vehicle App as next step.\n Open the main python file src/SeatAdjusterApp/seatadjuster.py file and set a breakpoint in line 68 Press F5 to start the Vehicle App to start a debug session and see the log output on the DEBUG CONSOLE  In the next step you will use a mqtt message to trigger this breakpoint.\nSend MQTT messages to Vehicle App Let’s send a message to your Vehicle App using the mqtt broker that is running in the background.\n  Make sure, Vehicle Api Mock and Seat Adjuster App are running.\n  Open VSMqtt extension in Visual Studio Code and connect to mosquitto (local)\n  Set Subscribe Topic = seatadjuster/setPosition/response and click subscribe.\n  Set Subscribe Topic = seatadjuster/currentPosition and click subscribe.\n  Set Publish Topic = seatadjuster/setPosition/request\n  Set and publish a dummy payload:\n{ \"position\": 300, \"requestId\": \"xyz\" }   Now your breakpoint in the Vehicle App gets hit and you can inspect everything in your debug session\n  After resuming execution (F5), a response from your Vehicle App is published to the response topic\n  You can see the response in the MQTT window.\n  Trigger your Github Workflows GitHub workflows are used to build the container image for the Vehicle App, run unit and integration tests, collect the test results and create a release documentation and publish the Vehicle App. A detailed description of the workflow you can find here.\nPrerequisites In order to run the workflow succesfully inside the SDV-Org, we are using a PAT of the technical user swd9be. He needs write access to all repos created from the template repository. Furthermore this user needs read access to the following repositories:\n vehicle-app-python-sdk vehicle-model-python license-check  When using the template outside of the SDV-Org some additional steps need to be done:\n create a personal access token  needs write access to your repo   create a secret  Name must be SDV_GITHUB_AUTOMATION_TOKEN   paste the PAT into the secret  Run GitHub Workflow  Make modification to your file, e.g. remove the last empty line from src/SeatAdjusterApp/seatadjuster.py Commit you change git add . git commit -m \"removed emtpy line\"  Push git push  Open your git repository in your favorite browser Navigate to Actions and go to CI Workflow Check Workflow Output, it should look like this:   Build you first release Now that the CI Workflow was successful, you are ready to build your first release. Your goal is to build a ready-to-deploy container image.\nRelease the Vehicle App to push it to the container registry  In order to deploy the Vehicle App you need to configure the container registry credentials first:  Open Settings, go to Secrets, click on Manage your environments and add repository secrets and add the following secret (button Add Secret):  Name: OTA_SYSTEM_CREDENTIALS Value: {  \"CONTAINER_REGISTRY \": \"\u003cyour container registry\u003e\",  \"REGISTRY_USER \": \"\u003cyour username\u003e\",  \"REGISTRY_PASSWORD \": \"\u003cyour password\u003e\" }      Open the Code page of your repository on GitHub.com and click on Create a new release in the Releases section on the right side Enter a version and click on Publish release  Note: you can start the verion with a v which will be removed though, e.g. “v1.0.0” will result in a “1.0.0” (see vesion-without-v).   The release workflow will be triggered  Open Actions on the repoitory and see the result    Next steps  Walkthrough: Create a Python Vehicle App Deploy runtime services in Kubernetes mode Develop and run integration tests for a Vehicle App  ","categories":"","description":"Learn how to setup and explore the provided development environment.\n","excerpt":"Learn how to setup and explore the provided development environment.\n","ref":"/velocitas-docs/docs/tutorials/quickstart/","tags":"","title":"Quickstart"},{"body":"Introduction The Python Vehicle App SDK consists of the following building blocks:\n  Vehicle Model Ontology: The SDK provides a set of model base classes for the creation of vehicle models.\n  Middleware integration: Vehicle Models can contain gRPC stubs to communicate with Vehicle Services. gRPC communication is integrated with the Dapr middleware for service discovery and OpenTelemetry tracing.\n  Fluent query \u0026 rule construction: Based on a concrete Vehicle Model, the SDK is able to generate queries and rules against the Vehicle Data Broker to access the real values of the data points that are defined in the vehicle model.\n  Publish \u0026 subscribe messaging: The SDK supports publishing messages to a MQTT broker and subscribing to topics of a MQTT broker.\n  Vehicle App abstraction: Last but not least the SDK provides a Vehicle App base class, which every Vehicle App derives from.\n  An overview of the Vehicle App SDK for Python and its dependencies is depicted in the following diagram:\nOverview of Python SDK architecture   Vehicle Model Ontology The Vehicle Model is a tree-based model where every branch in the tree, including the root, is derived from the Model base class.\nThe Vehicle Model Ontology consists of the following classes:\nModel A model contains services, data points and other models. It corresponds to branch entries in VSS or interfaces in DTDL or namespaces in VSC.\nModelCollection Specifications like VSS support a concept that is called Instances. It makes it possible to describe repeating definitions. In DTDL, such kind of structures may be modeled with Relationships. In the SDK, these structures are mapped with the ModelCollection class. A ModelCollection is a collection of models, which make it possible to reference an individual model either by a NamedRange (e.g., Row [1-3]), a Dictionary (e.g., “Left”, “Right”) or a combination of both.\nService Direct synchronous communication between Vehicle Apps and Vehicle Services is supposed to be facilitated over the gRPC protocol.\nThe SDK has its own Service base class, which provides a convenience API layer to access the exposed methods of exactly one gRPC endpoint of a Vehicle Service or another Vehicle App. Please see the Middleware Integration section for more details.\nDataPoint DataPoint is the base class for all data points. It corresponds to sensors/actuators in VSS or telemetry / properties in DTDL.\nData Points are the signals that are typically emitted by Vehicle Services.\nThe representation of a data point is a path starting with the root model, e.g.:\n Vehicle.Speed Vehicle.FuelLevel Vehicle.Cabin.Seat.Row1.Pos1.Position  Data points are defined as attributes of the model classes. The attribute name is the name of the data point without its path.\nTyped DataPoint classes Every primitive datatype has a corresponding typed data point class, which is derived from DataPoint (e.g., DataPointInt32, DataPointFloat, DataPointBool, DataPointString, etc.).\nExample An example of a Vehicle Model created with the described ontology is shown below:\n```Python  # import ontology classes from sdv import (  DataPointDouble,  Model,  Service,  DataPointInt32,  DataPointBool,  DataPointArray,  DataPointString,  ModelCollection,  NamedRange )  class Seat(Model):  def __init__(self, parent):  super().__init__(parent)  self.Position = DataPointBool(\"Position\", self)  self.IsOccupied = DataPointBool(\"IsOccupied\", self)  self.IsBelted = DataPointBool(\"IsBelted\", self)  self.Height = DataPointInt32(\"Height\", self)  self.Recline = DataPointInt32(\"Recline\", self)  class Cabin(Model):  def __init__(self, parent: Model):  super().__init__(parent)   self.DriverPosition = DataPointInt32(\"DriverPosition\", self)  self.Seat = ModelCollection[Seat](  [NamedRange(\"Row\", 1, 2), NamedRange(\"Pos\", 1, 3)], Seat(self)  )  class VehicleIdentification(Model):  def __init__(self, parent):  super().__init__(parent)  self.VIN = DataPointString(\"VIN\", self)  self.Model = DataPointString(\"Model\", self)  class CurrentLocation(Model):  def __init__(self, parent):  super().__init__(parent)  self.Latitude = DataPointDouble(\"Latitude\", self)  self.Longitude = DataPointDouble(\"Longitude\", self)  self.Timestamp = DataPointString(\"Timestamp\", self)  self.Altitude = DataPointDouble(\"Altitude\", self)  class Vehicle(Model):  def __init__(self):  super().__init__()  self.Speed = DataPointFloat(\"Speed\", self)  self.CurrentLocation = CurrentLocation(self)  self.Cabin = Cabin(self)  vehicle = Vehicle() Middleware integration gRPC Services Vehicle Services are expected to expose their public endpoints over the gRPC protocol. The related protobuf definitions are used to generate Python method stubs for the Vehicle Model to make it possible to call the methods of the Vehicle Services.\nModel integration Based on the .proto files of the Vehicle Services, the protocol buffers compiler generates special Python descriptors for all rpcs, messages, fields etc. The gRPC stubs are wrapped by a convenience layer class derived from Service that contains all the methods of the underlying protocol buffer specification.\nclass SeatService(Service):  def __init__(self):  super().__init__()  self._stub = SeatsStub(self.channel)   async def Move(self, seat: Seat):  response = await self._stub.Move(  MoveRequest(seat=seat), metadata=self.metadata  )  return response Service discovery The underlying gRPC channel is provided and managed by the Service base class of the SDK. It is also responsible for routing the method invocation to the service through dapr middleware. As a result, a dapr-app-id has to be assigned to every Service, so that dapr can discover the corresponding vehicle services. This dapr-app-id has to be specified as an environment variable named \u003cservice_name\u003e_DAPR_APP_ID.\nFluent query \u0026 rule construction A set of query methods like get(), where(), join() etc. are provided through the Model and DataPoint base classes. These functions make it possible to construct SQL-like queries and subscriptions in a fluent language, which are then transmitted through the gRPC interface to the Vehicle Data Broker.\nQuery examples The following examples show you how to query data points.\nGet single datapoint driver_pos: int = vehicle.Cabin.DriverPosition.get()  # Call to broker: # GetDataPoint(rule=\"SELECT Vehicle.Cabin.DriverPosition\") Get datapoints from multiple branches vehicle_data = vehicle.CurrentLocation.Latitude.join(  vehicle.CurrentLocation.Longitude).get()  print(f'  Latitude: {vehicle_data.CurrentLocation.Latitude}  Longitude: {vehicle_data.CurrentLocation.Longitude}  # Call to broker: # GetDataPoint(rule=\"SELECT Vehicle.CurrentLocation.Latitude, CurrentLocation.Longitude\") Subscription examples Subscribe and Unsubscribe to a single datapoint  self.rule = (  await self.vehicle.Cabin.Seat.element_at(2,1).Position  .subscribe(self.on_seat_position_change) )  def on_seat_position_change(int position):  print(f'Seat position changed to {position}')  # Call to broker: # Subscribe(rule=\"SELECT Vehicle.Cabin.Seat.Row2.Pos1.Position\")  # If needed, the subscription can be stopped like this: await self.rule.subscription.unsubscribe() Subscribe to a single datapoint with a filter vehicle.Cabin.Seat.element_at(2,1).Position.where(  \"Cabin.Seat.Row2.Pos1.Position \u003e 50\")  .subscribe(on_seat_position_change)  def on_seat_position_change(int position):  print(f'Seat position changed to {position}')  # Call to broker: # Subscribe(rule=\"SELECT Vehicle.Cabin.Seat.Row2.Pos1.Position WHERE Vehicle.Cabin.Seat.Row2.Pos1.Position \u003e 50\") Publish \u0026 subscribe messaging The SDK supports publishing messages to a MQTT broker and subscribing to topics of a MQTT broker. By leveraging the dapr pub/sub building block for this purpose, the low-level MQTT communication is abstracted away from the Vehicle App developer. Especially the physical address and port of the MQTT broker is no longer configured in the Vehicle App itself, but rather is part of the dapr configuration, which is outside of the Vehicle App.\nPublish MQTT Messages MQTT messages can be published easily with the publish_mqtt_event() method, inherited from VehicleApp base class:\nawait self.publish_mqtt_event(  \"seatadjuster/currentPosition\", json.dumps(req_data)) Subscribe to MQTT Topics Subscriptions to MQTT topics can be easily established with the subscribe_topic() annotation. The annotation needs to be applied to a method of the Vehicle App class.\n@subscribe_topic(\"seatadjuster/setPosition/request\") async def on_set_position_request_received(self, data: str) -\u003e None:  data = json.loads(data)  logger.info(\"Set Position Request received: data=%s\", data) Under the hood, the vehicle app creates a grpc endpoint on port 50008, which is exposed to the dapr middleware. The dapr middleware will then subscribe to the MQTT broker and forward the messages to the vehicle app.\nTo change the app port, set it in the main() method of the app:\nfrom sdv import conf  async def main():  conf.DAPR_APP_PORT = \u003cyour port\u003e Vehicle App abstraction Vehicle Apps are inherited from the VehicleApp base class. This enables the Vehicle App to use the Publish \u0026 subscribe messaging and the Vehicle Data Broker.\nThe Vehicle Model instance is passed to the __init__ method of the VehicleApp class and should be stored in a self.vehicle attribute, to be used in event handler functions.\nFinally, the run() method of the VehicleApp class is called to start the Vehicle App and register all MQTT topic and Vehicle Data Broker subscriptions. The subscriptions are based on asyncio, which makes it necessary to call the run() method with an active asyncio event_loop.\nA typical skeleton of a Vehicle App looks like this:\n ```Python class SeatAdjusterApp(VehicleApp):  def __init__(self, vehicle: Vehicle):  super().__init__()  self.vehicle = vehicle  async def main():  seat_adjuster_talent = SeatAdjusterApp(vehicle)  await seat_adjuster_talent.run()   LOOP = asyncio.get_event_loop() LOOP.add_signal_handler(signal.SIGTERM, LOOP.stop) LOOP.run_until_complete(main()) LOOP.close() ","categories":"","description":"Learn more about the provided Python Vehicle App SDK.\n","excerpt":"Learn more about the provided Python Vehicle App SDK.\n","ref":"/velocitas-docs/docs/concepts/python_vehicle_app_sdk/","tags":"","title":"Python Vehicle App SDK"},{"body":" We recommend that you make yourself familiar with the Python Vehicle App SDK Overview first, before going through this tutorial.\n This tutorial will show you how to:\n Set up a Python Package Create a Python Vehicle Model Add Vehicle Services Distribute your Python Vehicle Model  Prerequisites  Visual Studio Code with the Python extension installed. For information on how to install extensions on Visual Studio Code, see VS Code Extension Marketplace.  Create a Python Vehicle Model A Vehicle Model should be defined in its own Python Package. This makes it possible to distribute the Vehicle Model later as a standalone package and to use it in different Vehicle App projects. A Vehicle Model can be created in one of two ways.\n  Create a Python Vehicle Model from VSS specification A Vehicle Model can be generated from the VSS spec. vehicle-model-generator creates a Vehicle Model from the given vspec specification and also generates a package for use in Vehicle App projects.\nFollow the steps to generate a Vehicle Model.\n  Clone the vehicle-model-generator repository in a container volume.\n  In this container volume, clone the vehicle-signal-specification repository.\ngit clone https://github.com/COVESA/vehicle_signal_specification After cloning if a user wants to refer to a particular branch they can checkout that branch afterwards.\ncd vehicle_signal_specification git checkout \u003cbranch-name\u003e   Execute the command\npython3 gen_vehicle_model.py -I ./vehicle_signal_specification/spec ./vehicle_signal_specification/spec/VehicleSignalSpecification.vspec -T sdv_model -N sdv_model This creates a sdv_model directory in the root of repository along with a setup.py file. To have a custom model name, refer to README of vehicle-model-generator repository.\n  Change the version of package in setup.py manually (defaults to 0.1.0).\n  Now the newly generated sdv_model can be used for distribution. (See Distributing your Python Vehicle Model)\n    Create a Python Vehicle Model Manually Setup a Python Package manually A Vehicle Model should be defined in its own Python Package. This allows to distribute the Vehicle Model later as a standalone package and to use it in different Vehicle App projects.\nThe name of the Vehicle Model package will be my_vehicle_model for this walkthrough.\n  Start Visual Studio Code\n  Select File \u003e Open Folder (File \u003e Open… on macOS) from the main menu.\n  In the Open Folder dialog, create a my_vehicle_model folder and select it. Then click Select Folder (Open on macOS).\n  Create a new file setup.py under my_vehicle_model:\nfrom setuptools import setup  setup(name='my_vehicle_model',  version='0.1',  description='My Vehicle Model',  packages=['my_vehicle_model'],  zip_safe=False) This is the Python package distribution script.\n  Create an empty folder my_vehicle_model under my_vehicle_model.\n  Create a new file __init__.py under my_vehicle_model/my_vehicle_model.\n  At this point the source tree of the Python package should look like this:\nmy_vehicle_model ├── my_vehicle_model │ └── __init__.py └── setup.py To verify that the package is created correctly, install it locally:\npip3 install . The output of the above command should look like this:\nDefaulting to user installation because normal site-packages is not writeable Processing /home/user/projects/my-vehicle-model Preparing metadata (setup.py) ... done Building wheels for collected packages: my-vehicle-model Building wheel for my-vehicle-model (setup.py) ... done Created wheel for my-vehicle-model: filename=my_vehicle_model-0.1-py3-none-any.whl size=1238 sha256=a619bc9fbea21d587f9f0b1c1c1134ca07e1d9d1fdc1a451da93d918723ce2a2 Stored in directory: /home/user/.cache/pip/wheels/95/c8/a8/80545fb4ff73c974ac1716a7bff6f7f753f92022c41c2e376f Successfully built my-vehicle-model Installing collected packages: my-vehicle-model Successfully installed my-vehicle-model-0.1 Finally, uninstall the package again:\npip3 uninstall my_vehicle_model Add Vehicle Models manually   Install the Python Vehicle App SDK:\n```bash pip3 install git+https://github.com/eclipse-velocitas/vehicle-app-python-sdk.git@v0.4.0 ``` The output of the above command should end with: ```bash Successfully installed sdv-0.4.0 ```  Now it is time to add some Vehicle Models to the Python package. At the end of this section you will have a Vehicle Model, that contains a Cabin model, a Seatmodel and has the following tree structure:\nVehicle └── Cabin └── Seat (Row, Pos)    Create a new file Seat.py under my_vehicle_model/my_vehicle_model:\nfrom sdv.model import Model  class Seat(Model):   def __init__(self, parent):  super().__init__(parent)  self.Position = DataPointFloat(\"Position\", self) This creates the Seat model with a single data point of type float named Position.\n  Create a new file Cabin.py under my_vehicle_model/my_vehicle_model:\nfrom sdv.model import Model  class Cabin(Model):   def __init__(self, parent):  super().__init__(parent)   self.Seat = ModelCollection[Seat](  [NamedRange(\"Row\", 1, 2), NamedRange(\"Pos\", 1, 3)], Seat(self)  ) This creates the Cabin model, which contains a set of six Seat models, referenced by their rows and positions:\n row=1, pos=1 row=1, pos=2 row=1, pos=3 row=2, pos=1 row=2, pos=2 row=2, pos=3    Create a new file vehicle.py under my_vehicle_model/my_vehicle_model:\nfrom sdv.model import Model from my_vehicle_model.Cabin import Cabin   class Vehicle(Model):  \"\"\"Vehicle model\"\"\"   def __init__(self):  super().__init__()  self.Speed = DataPointFloat(\"Speed\", self)  self.Cabin = Cabin(self)  vehicle = Vehicle()   The root model of the Vehicle Model tree should be called Vehicle by convention and is specified, by setting parent to None. For all other models a parent model must be specified as the 2nd argument of the Model constructor, as can be seen by the Cabin and the Seat models above.\nA singleton instance of the Vehicle Model called vehicle is created at the end of the file. This instance is supposed to be used in the Vehicle Apps. Creating multiple instances of the Vehicle Model should be avoided for performance reasons.\n  Add a Vehicle Service In this section, we add the SeatService vehicle service to the Vehicle Model.\n  Create a new folder proto under my_vehicle_model/my_vehicle_model.\n  Create a new file seats.proto under my_vehicle_model/my_vehicle_model/proto:\nsyntax = \"proto3\";package sdv.edge.comfort.seats.v1;service Seats { rpc Move(MoveRequest) returns (MoveReply); rpc MoveComponent(MoveComponentRequest) returns (MoveComponentReply); rpc CurrentPosition(CurrentPositionRequest) returns (CurrentPositionReply);}message MoveRequest { Seat seat = 1; // The desired seat position }message MoveReply {}message MoveComponentRequest { SeatLocation seat = 1; // The seat location to change  SeatComponent component = 2; // The component position to change  int32 position = 3; // The desired position to move the component to }message MoveComponentReply {}message CurrentPositionRequest { uint32 row = 1; // The row of the desired seat (1 - front most)  uint32 index = 2; // The position in the addressed row (1 - left most) }message CurrentPositionReply { Seat seat = 1; // The seat state that was requested }message Seat { SeatLocation location = 1; // The location of the seat in the vehicle  Position position = 2; // The various positions of the seat }message SeatLocation { uint32 row = 1; // The row, front 1 and +1 toward rear  uint32 index = 2; // The index within the row, 1 left most, +1 toward right }message Position { int32 base = 1; // The position of the base 0 front, 1000 back  int32 cushion = 2; // The position of the cushion 0 short, 1000 long  int32 lumbar = 3; // The position of the lumbar support  int32 side_bolster = 4; // The position of the side bolster  int32 head_restraint = 5; // The position of the head restraint 0 down, 1000 up }enum SeatComponent { BASE = 0; CUSHION = 1; LUMBAR = 2; SIDE_BOLSTER = 3; HEAD_RESTRAINT = 4;}This is the protocol buffers message definition of the SeatService, which is expected to be provided by the vehicle service.\n  Install the grpcio tools including mypy types to generate the python classes out of the proto-file:\npip3 install grpcio-tools mypy_protobuf   Generate Python classes from the SeatService message definition:\npython3 -m grpc_tools.protoc -I my_vehicle_model/proto --grpc_python_out=./my_vehicle_model/proto --python_out=./my_vehicle_model/proto --mypy_out=./my_vehicle_model/proto my_vehicle_model/proto/seats.proto This creates the following grpc files under the proto folder:\n seats_pb2.py seats_pb2_grpc.py seats_pb2.pyi    Create the SeatService class and wrap the gRPC service:\nfrom sdv.model import Service  from my_vehicle_model.proto.seats_pb2 import (  CurrentPositionRequest,  MoveComponentRequest,  MoveRequest,  Seat,  SeatComponent,  SeatLocation, ) from my_vehicle_model.proto.seats_pb2_grpc import SeatsStub   class SeatService(Service):  \"SeatService model\"   def __init__(self):  super().__init__()  self._stub = SeatsStub(self.channel)   async def Move(self, seat: Seat):  response = await self._stub.Move(MoveRequest(seat=seat), metadata=self.metadata)  return response   async def MoveComponent(  self,  seatLocation: SeatLocation,  component: SeatComponent,  position: int,  ):  response = await self._stub.MoveComponent(  MoveComponentRequest(  seat=seatLocation,  component=component, # type: ignore  position=position,  ),  metadata=self.metadata,  )  return response   async def CurrentPosition(self, row: int, index: int):  response = await self._stub.CurrentPosition(  CurrentPositionRequest(row=row, index=index),  metadata=self.metadata,  )  return response Some important remarks about the wrapping SeatService class shown above:\n The SeatService class must derive from the Service class provided by the Python SDK. The SeatService class must use the grpc channel from the Service base class and provide it to the _stub in the __init__ method. This allows the SDK to manage the physical connection to the grpc service and use service discovery of the middleware. Every method needs to pass the metadata from the Service base class to the gRPC call. This is done by passing the self.metadata argument to the metadata of the gRPC call.    Distributing your Python Vehicle Model Now you a have a Python package containing your first Python Vehicle Model and it is time to distribute it. There is nothing special about the distribution of this package, since it is just an ordinary Python package. Check out the Python Packaging User Guide to learn more about packaging and package distribution in Python.\nDistribute to single Vehicle App If you want to distribute your Python Vehicle Model to a single Vehicle App, you can do so by copying the entire folder my_vehicle_model under the src folder of your Vehicle App repository and treat is a sub-package of the Vehicle App.\n Create a new folder my_vehicle_model under src in your Vehicle App repository. Copy the my_vehicle_model folder to the src folder of your Vehicle App repository. Import the package my_vehicle_model in your Vehicle App:  from \u003cmy_app\u003e.my_vehicle_model import vehicle  ...  my_app = MyVehicleApp(vehicle) Distribute inside an organization If you want to distribute your Python Vehicle Model inside an organization and use it to develop multiple Vehicle Apps, you can do so by creating a dedicated Git repository and copying the files there.\n  Create new Git repository called my_vehicle_model\n  Copy the content under my_vehicle_model to the repository.\n  Release the Vehicle Model by creating a version tag (e.g., v1.0.0).\n  Install the Vehicle Model package to your Vehicle App:\npip3 install git+https://github.com/\u003cyourorg\u003e/my_vehicle_model.git@v1.0.0   Import the package my_vehicle_model in your Vehicle App and use it as shown in the previous section.\n  Distribute publicly as open source If you want to distribute your Python Vehicle Model publicly, you can do so by creating a Python package and distributing it on the Python Package Index (PyPI). PyPi is a repository of software for the Python programming language and helps you find and install software developed and shared by the Python community. If you use the pip command, you are already using PyPI.\nDetailed instructions on how to make a Python package available on PyPI can be found here.\n","categories":"","description":"Learn how to create a simple Python Vehicle Model with Visual Studio Code and the Python Vehicle App SDK.\n","excerpt":"Learn how to create a simple Python Vehicle Model with Visual Studio …","ref":"/velocitas-docs/docs/tutorials/tutorial_how_to_create_a_vehicle_model/","tags":"","title":"Python Vehicle Model Creation"},{"body":" We recommend that you make yourself familiar with the Python Vehicle App SDK first, before going through this tutorial.\n The following information describes how to develop and test the sample Vehicle App that is included in the template repository. You will learn how to use the Vehicle App SDK and how to interact with the Vehicle Model.\nOnce you have completed all steps, you will have a solid understanding of the development workflow and you will be able to reuse the template repository for your own Vehicle App development project.\nDevelop your first Vehicle App This section describes how to develop your first Vehicle App. Before you start building a new Vehicle App, make sure you have already read the other manuals:\n Setup and Explore Development Enviroment How to create a Vehicle Model  Once you have established a working environment, you will be able to start developing your first Vehicle App.\nFor this purpose, we assume a usecase having a vehicle where we can change the positions of the seats and also get their current positions.\nAt first, you have to create the main python script called run.py in src/. All the relevant code for new Vehicle App goes there. Afterwards, there are several steps you need to consider when developing the app:\n Manage your imports Enable logging Initialize your class Start the app  Manage your imports Before you start development in the run.py you just created, it will be necessary to include the imports required, which you will understand better later through the development:\nimport asyncio import json import logging import signal  from sdv.util.log import get_default_date_format, get_default_log_format from sdv.vehicle_app import VehicleApp, subscribe_data_points, subscribe_topic  from set_position_request_processor import SetPositionRequestProcessor from vehicle_model.Vehicle import Vehicle Enable logging The following logging configuration applies the default log format provided by the SDK and sets the log level to INFO:\nlogging.basicConfig(format=get_default_log_format(), datefmt=get_default_date_format()) logging.getLogger().setLevel(\"INFO\") logger = logging.getLogger(__name__) Initialize your class The main class of your new Vehicle App needs to inherit the VehicleApp provided by the SDK.\nclass SeatAdjusterApp(VehicleApp): In class initialization, you have to pass an instance of the Vehicle Model:\ndef __init__(self, vehicle_client: Vehicle):  super().__init__()  self.vehicle_client = vehicle_client We save the vehicle object to use it in our app. Now, you have initialized the app and can continue developing relevant methods.\nStart the app Here’s an example of how to start the SeatAdjuster App we just developed:\nasync def main():  \"\"\"Main function\"\"\"  logger.info(\"Starting seat adjuster app...\")  seat_adjuster_talent = SeatAdjusterApp(vehicle)  await seat_adjuster_talent.run()  LOOP = asyncio.get_event_loop() LOOP.add_signal_handler(signal.SIGTERM, LOOP.stop) LOOP.run_until_complete(main()) LOOP.close() The app is now running. In order to use it properly, we will enhance the app with more features in the next sections.\nVehicle Model In order to facilitate the implementation, the whole vehicle is abstracted into model classes. Please check tutorial about creating models for more details about this topic. In this section, the focus is on using the models.\nImport the model The first thing you need to do to get access to the Vehicle Model. In the section about distributing a model, you got to know the different methods.\nIf you just want to use your model in one app, you can simply copy the classes into your src-folder. In this example, you find the classes inside the vehicle_model-folder. As you have already seen in the section about initializing the app, we need the vehicle modelto use the app.\nAs you know, the model has a single Datapoint for the speed and a reference to the cabin-model.\nAccessing the speed can be done via\nvehicle_speed = await self.vehicle_client.Speed.get() As the get-method of the Datapoint-class there is a coroutine and you have to use the await keyword when using it.\nIf you want to get deeper inside the vehicle, to access a single seat for example, you just have to go the model-chain down:\nself.DriverSeatPosition = await self.vehicle_client.Cabin.Seat.Row1.Pos1.Position.get() Subscribtion to Datapoints As you have already seen in the Vehicle Models, Datapoints are objects that contain just a single type of data. You can also use them directly in your app as already seen in the section above with the example of the vehicle speed.\nIf you want to get notified about the changes of a Datapoint, you can subscribe to this event. To get notified when, for example, the position of a seat changes, you create a method, which is annotated with@subscribe_data_points defined by the whole path to the Datapoint of interest.\nIn the method body, you can handle the information and send out MQTT messages. Notice that you get the data as a JSON-object and have to handle it accordingly.\n@subscribe_data_points(\"Vehicle.Cabin.Seat.Row1.Pos1.Position\") async def on_vehicle_seat_change(self, data):  resp_data = data.fields[\"Vehicle.Cabin.Seat.Row1.Pos1.Position\"].int32_value  req_data = {\"position\": resp_data}  logger.info(\"Current Position of the Vehicle Seat is: %s\", req_data)  try:  await self.publish_mqtt_event(  \"seatadjuster/currentPosition\", json.dumps(req_data)  )  except Exception as ex:  logger.info(\"Unable to get Current Seat Position, Exception: %s\", ex)  resp_data = {\"requestId\": data[\"requestId\"], \"status\": 1, \"message\": ex}  await self.publish_mqtt_event(  \"seatadjuster/currentPosition\", json.dumps(resp_data)  ) Services Services are used to communicate with other parts of the vehicle. Please read the basics about them here.\nThe following few lines show you how to use the MoveComponent-method of the SeatService you have created:\nlocation = SeatLocation(row=1, index=1) await self.vehicle_client.Cabin.SeatService.MoveComponent(  location, BASE, 300  ) We have to use the await keyword here, since the service methods are co-routines. In order to know which seat to move, you have to pass a SeatLocation object as the first parameter. The second argument specifies the component to be moved. The possible components are defined in the proto-files. The last parameter to be passed into the method is the final position of the component.\nMQTT Interaction with other Vehicle Apps or the cloud is enabled by using Mosquitto MQTT Broker. The MQTT broker runs inside a docker image, which is started automatically after starting the DevContainer.\nIn the general section about the Vehicle App, you already tested sending MQTT messages to the app. In the previous sections, you generally saw how to use Vehicle Models, Datapoints and GRPC Services. In this section, you will learn how to combine them with MQTT. In order to receive the MQTT messages inside your app, @subscribe_topic annotation needs to be used with the specified topic. In the method, you can process the data or forward it to another method that handles processing and also provides a response.\n@subscribe_topic(\"seatadjuster/setPosition/request\") async def on_set_position_request_received(self, data: str) -\u003e None:  \"\"\"Handle set position request from GUI app from MQTT topic\"\"\"  data = json.loads(data)  logger.info(\"Set Position Request received: data=%s\", data) # noqa: E501  await self._on_set_position_request_received(  data, \"seatadjuster/setPosition/response\"  ) This method contains logic to execute requested operations or if that is not possible, respond with an error message. Another class, which you see next, is used to process the request.\nasync def _on_set_position_request_received(  self, data: str, resp_topic: str ) -\u003e None:  vehicle_speed = await self.vehicle_client.Speed.get()   if vehicle_speed == 0:  processor = SetPositionRequestProcessor(self.vehicle_client)  await processor.process(data, resp_topic, self)  else:  error_msg = f\"\"\"Not allowed to move seat because vehicle speed is {vehicle_speed}and not 0\"\"\"  logger.warning(error_msg)  resp_data = {  \"requestId\": data[\"requestId\"], # type: ignore  \"status\": 1,  \"message\": error_msg,  }  await self.publish_mqtt_event(resp_topic, json.dumps(resp_data)) The RequestProcessor class contains code responsible for processing the position request, including relevant MQTT communication.\nclass SetPositionRequestProcessor:  \"\"\"A class to process position requests.\"\"\"   def __init__(self, vehicle_client: Vehicle):  self.vehicle_client = vehicle_client   async def process(self, data: str, resp_topic: str, app: VehicleApp):  \"\"\"Process the position request.\"\"\"  resp_data = await self.__get_processed_response(data)  await self.__publish_data_to_topic(resp_data, resp_topic, app)   async def __get_processed_response(self, data):  try:  location = SeatLocation(row=1, index=1)  await self.vehicle_client.Cabin.SeatService.MoveComponent(  location, BASE, data[\"position\"] # type: ignore  )  resp_data = {\"requestId\": data[\"requestId\"], \"result\": {\"status\": 0}}  except Exception as ex:  resp_data = {  \"requestId\": data[\"requestId\"],  \"result\": {\"status\": 1, \"message\": self.__get_error_message_from(ex)},  }  return resp_data   async def __publish_data_to_topic(  self, resp_data: dict, resp_topic: str, app: VehicleApp  ):  try:  await app.publish_mqtt_event(resp_topic, json.dumps(resp_data))  except Exception as ex:  logger.error(self.__get_error_message_from(ex))   def __get_error_message_from(self, ex: Exception):  return f\"Exception details: {ex}\" UnitTests Unit testing is an important part of the development, so let’s have a look at how to do that. You can find some example tests in test_set_position_request_processor.py. First, you have to import the relevant packages for unit testing and everything you need for your implementation:\nfrom unittest import mock import pytest  from sdv.vehicle_app import VehicleApp from vehicle_model.proto.seats_pb2 import BASE, SeatLocation from vehicle_model.SeatService import SeatService @pytest.mark.asyncio async def test_for_publish_to_topic():  with mock.patch.object(  VehicleApp, \"publish_mqtt_event\", new_callable=mock.AsyncMock, return_value=-1  ):  response = await VehicleApp.publish_mqtt_event(  str(\"sampleTopic\"), get_sample_request_data()  )  assert response == -1   def get_sample_request_data():  return {\"position\": 330, \"requestId\": \"123456789\"} Looking at a test you notice the annotation @pytest.mark.asyncio. This is required if the test is defined as a co-routine. The next step is to create a mock from all the external dependencies. The method takes 4 arguments: first is the object to be mocked, second the method for which you want to modify the return value, third a callable and the last argument is the return value. After creating the mock, you can test the method and check the response. Use asserts to make your test fail if the response does not match.\nSee the results Once the implementation is done, it is time to run and debug the app.\nRun your App If you want to run the app together with a Dapr sidecar and use the Dapr middleware, you have to use the “dapr run …” command to start your app:\ndapr run --app-id seatadjuster --app-protocol grpc --app-port 50008 --config ./.dapr/config.yaml --components-path ./.dapr/components python3 ./src/run.py You already have seen this command and how to check if it is working in the general setup.\n2 parameters may be unclear in this command:\n the config file config.yaml the components-path  For now, you just need to know that these parameters are needed to make everything work together.\nThe config.yaml has to be placed in the folder called .daprand has the following content:\napiVersion:dapr.io/v1alpha1kind:Configurationmetadata:name:configspec:tracing:samplingRate:\"1\"zipkin:endpointAddress:http://localhost:9411/api/v2/spansfeatures:- name:proxy.grpcenabled:trueAn important part is the enabling of the GRPC proxy, to make the communication work.\nInside the .dapr folder you find another folder called components. There you only find one configuration file for the MQTT communication with the following content:\napiVersion:dapr.io/v1alpha1kind:Componentmetadata:name:mqtt-pubsubnamespace:defaultspec:type:pubsub.mqttversion:v1metadata:- name:urlvalue:\"mqtt://localhost:1883\"- name:qosvalue:1- name:retainvalue:\"false\"- name:cleanSessionvalue:\"false\"If you want to know more about dapr and the configuration, please visit https://dapr.io\nDebug your Vehicle App In the introduction about debugging, you saw how to start a debugging session. In this section, you will learn what is happening in the background.\nIn order to be able to debug your code, you need to add some configs in Visual Studio Code. You find the files in the .vscode folder. The main entrypoint is the launch.json. All configurations are stored here. Currently there is only one for the SeatAdjuster App.\n\"configurations\": [  {  \"type\": \"python\",  \"justMyCode\": false,  \"request\": \"launch\",  \"name\": \"SeatAdjuster\",  \"program\": \"${workspaceFolder}/src/run.py\",  \"console\": \"integratedTerminal\",  \"preLaunchTask\": \"dapr-SeatAdjuster-run\",  \"postDebugTask\": \"dapr-SeatAdjuster-stop\",  \"env\": {  \"DAPR_GRPC_PORT\":\"50001\",  \"SEATSERVICE_DAPR_APP_ID\": \"seatservice\",  \"VEHICLEDATABROKER_DAPR_APP_ID\": \"vehicledatabroker\"  }  } ] We specify which python-script to run using the program key. With the preLaunchTask and postDebugTask keys, you can also specify tasks to run before or after debugging. In this example, DAPR is set up to start the app before and stop it again after debugging. Below you can see the 2 tasks.\n{  \"label\": \"dapr-SeatAdjuster-run\",  \"appId\": \"seatadjuster\",  \"appPort\": 50008,  \"componentsPath\": \"./.dapr/components\",  \"config\": \"./.dapr/config.yaml\",  \"appProtocol\": \"grpc\",  \"type\": \"dapr\",  \"args\": [  \"--dapr-grpc-port\",  \"50001\",  \"--dapr-http-port\",  \"3500\"  ], } {  \"label\": \"dapr-SeatAdjuster-stop\",  \"type\": \"shell\",  \"command\": [  \"dapr stop --app-id seatadjuster\"  ],  \"presentation\": {  \"close\": true,  \"reveal\": \"never\"  }, } Lastly, the environment variables can also be specified.\nYou can adapt the JSON to your needs (e.g., change the ports, add new tasks) or even add a completely new configuration for another Vehicle App.\nOnce you are done, you have to switch to the debugging tab (sidebar on the left) and select your configuration using the dropdown on the top. You can now start the debug session by clicking the play button or F5. Debugging is now as simple as in every other IDE, just place your breakpoints and follow the flow of your Vehicle App.\nNext steps  Walkthrough: Deploy a Python Vehicle App with Helm  ","categories":"","description":"Learn how to develop and test the Vehicle App.\n","excerpt":"Learn how to develop and test the Vehicle App.\n","ref":"/velocitas-docs/docs/tutorials/tutorial_how_to_create_a_vehicle_app/","tags":"","title":"Python Vehicle App Development"},{"body":"The Velocitas project uses a common deployment model. It uses OCI-compliant containers to increase the flexibility for the support of different programming languages and runtimes, which accelerates innovation and development. OCI-compliant containers also allow for a standardized yet flexible deployment process, which increases the ease of operation. Using OCI-compliant is portable to different architectures as long as there is support for OCI-compliant containers on the desired platform (e.g., like a container runtime for arm32, arm64 or amd64).\nGuiding principles The deployment model is guided by the following principles\n Applications are provided as OCI-compatible container images. The container runtime offers a Kubernetes-compatible control plane and API to manage the container lifecycle. Helm charts are used as deployment descriptor specification.  The template projects provided come with a preconfigured developer toolchain that accelerates the development process. The developer toolchain ensures an easy creation through a high-degree of automation, of all required artifacts which are needed to follow the Velocitas principles.\nTesting your container during development The Velocitas project provides developers with a repository template and devcontainer that contains everything to build a containerized version of your app locally and test it. Check out our tutorial e.g., for python template (https://github.com/eclipse-velocitas/vehicle-app-python-template) to learn more.\nAutomated container image builds Velocitas uses GitHub workflows to automate the creation of your containerized application. A workflow is started with every increment of your application code that you push to your GitHub repository. The workflow creates a containerized version of your application and stores this container image in a registry. Further actions are carried out using this container (e.g., integration tests).\nThe workflows are set up to support multi-platform container creation and generate container images for amd64 and arm64 out of the box. This provides a great starting point for developers and lets you add additional support for further platforms easily.\nLearn more about the concepts of the Velocitas build and release workflows and check out the example GitHub workflows in our repositories for python (https://github.com/eclipse-velocitas/vehicle-app-python-template/blob/main/.github/workflows/ci.yml).\nNext steps  Walkthrough: Deploy a Python Vehicle App with Helm  ","categories":"","description":"Learn more about our deployment model and guiding principles.\n","excerpt":"Learn more about our deployment model and guiding principles.\n","ref":"/velocitas-docs/docs/concepts/runtime-deployment-model/","tags":"","title":"Runtime and Deployment Model"},{"body":"The Velocitas project provides a two-stage process for the development, continuous integration, and release of a new version of a Vehicle App.\n  Stage 1 - Build \u0026 Test On every new push to the main branch, a GitHub workflow is automatically executed to build your application as a container (optionally for different platforms), runs automated tests and code quality checks, and stores all results as GitHub artifacts or in a container registry for future reference.\nThe workflow provides quick feedback during development and improves efficient collaboration.\n  Stage 2 - Release Once the application is ready to be released in a new version, a dedicated release workflow is automatically executed as soon as you create a new release via GitHub.\nThe workflow bundles all relevant artifacts into one tagged set of files and makes it possible to push this information to the preferred OTA (over-the-air update) system of your choice or use the information for quality assurance and documentation.\n  The following illustrates the different workflows, actions and artifacts that are automatically created for you. Both workflows are intended as a sensible baseline and can be extended and adapted to your own project’s needs.\nCI Workflow (ci.yml) The CI workflow is triggered on every commit to the main branch and contains a set of different actions that cover:\n Building a container for the app - actions create a containerized version of the Vehicle App, the actions also support creating an image for multiple platforms. Scanning for vulnerabilities - actions scan your code and container for vulnerabilities and in case of findings the workflow will be marked as “failed”. Running unit tests \u0026 code coverage - actions run unit tests and calculate code coverage for your application, in case of errors or unsatisfactory code coverage, the workflow will be marked as “failed”. Running integration tests - actions provision a runtime and deploy all required services as containers together with your containerized application to allow for automatically executing integration test cases. In case the test cases fail, the workflow will be marke as “failed”. Storing scan \u0026 test results as GitHub action artifacts - actions store results from the previously mentioned actions for further reference or download as Github Action Artifacts. Publish container images to GitHub Container Registry - at the end of the workflow, the container images created are stored in a Github Container Registry so that they can be referenced by the release-workflow later.  Release Workflow (release.yml) The Release workflow is triggered as soon as the main branch is ready for release and the Vehicle App developer creates a new GitHub release. This can be done manually through the GitHub UI.\nOn creating a new release with a specific new version, GitHub creates a tag and automatically runs the Release workflow defined in .github/workflows/release.yml, given that CI workflow has run successfully for the current commit on the main branch.\nThe set of actions included in the Release workflow cover:\n Generating and verifying QA information - actions load the QA information from GitHub artifacts stored for the same commit reference and verify it. Additionally, release documentation is generated and added to the GitHub release. If there is no information available for the current commit, the release workflow will fail. Pull \u0026 label container image - actions pull the Vehicle App container image based on the current commit hash from the GitHub registry and label it with the specified tag version. If the image cannot be found, the workflow will fail. Publish to container registry - actions publish your container image and helm charts to your preferred container registry, which is referenced by your preferred OTA (over-the-air update) system.  GitHub Actions artifacts GitHub Actions artifacts are used for storing data, which is generated by the CI workflow and referenced by the Release workflow. This saves time during workflow runs because we don’t have to create artifacts multiple times.\nGitHub Actions artifacts always have a retention period, which is 90 days per default, but may be configured differently in the specific GitHub organization. After this period, the QA info gets purged automatically. If that is the case, a re-run of the CI workflow is required to re-generate the QA info, afterwards a release can be created.\nContainer Registry The GitHub container registry is used for storing container images, which are generated by the CI workflow and leveraged by the Release workflow.\nThe GitHub container registry does not have an automatic cleanup and keeps container images as long as they are not deleted. It is recommended that you automate the removal of older images to limit storage size and costs.\nFurther information Versioning Vehicle App image versions are set to the Git tag name during release. Though any versioning scheme can be adopted, the usage of semantic versions is recommended.\nIf the tag name contains a semantic version, the leading v will be trimmed. Example: A tag name of v1.0.0 will lead to version 1.0.0 of the Vehicle App container.\nMaintaining multiple versions If there is a need to maintain multiple versions of a Vehicle App, e.g., to hotfix the production version while working on a new version at the same time or to support multiple versions in production, create and use release branches.\nThe release process would be the same as described in the overview, except that a release branch (e.g., release/v1.0) is created before the release step and the GitHub release is based on the release branch rather than the main branch. For hotfixes, release branches may be created retroactively from the release tag, if needed.\n","categories":"","description":"Learn more about the provided continuous integration, and release process of a Vehicle App.\n","excerpt":"Learn more about the provided continuous integration, and release …","ref":"/velocitas-docs/docs/concepts/vehicle_app_releases/","tags":"","title":"Build and Release Process"},{"body":"","categories":"","description":"Learn how to run the  Vehicle App Runtime Services locally or in Kubernetes.\n","excerpt":"Learn how to run the  Vehicle App Runtime Services locally or in …","ref":"/velocitas-docs/docs/tutorials/vehicle-app-runtime/","tags":"","title":"Run Vehicle App Runtime Services"},{"body":"","categories":"","description":"Explore the basic concepts of Eclipse Velocity™.\n","excerpt":"Explore the basic concepts of Eclipse Velocity™.\n","ref":"/velocitas-docs/docs/concepts/","tags":"","title":"Concepts"},{"body":"To be sure that a newly created Vehicle App will run together with the Vehicle Data Broker and potentially other dependant Vehicle Services or Vehicle Apps, it’s essential to write integration tests along with developing the app.\nTo execute an integration test, the dependant components need to be running and accessible from the test runner. This guide will describe how integration tests can be written and integrated in the CI pipeline so that they are executed automatically when building the application.\nQuickstart  Make sure that the local execution of runtime components is working and started. Start the application (Debugger or run as task). Extend the test file /test/integration_test.py or create a new test file. Run/debug tests with the Visual Studio Code Test runner.  Runtime components To be able to test the Vehicle App in an integrated way, the following components should be running:\n Dapr Mosquitto Vehicle Data Broker Vehicle Services  We distinguish between two environments for executing the Vehicle App and the runtime components:\n Local execution: components are running locally in the development environment Kubernetes execution: components (and application) are deployed and running in a Kubernetes control plane (e.g., K3D)  Local Execution First, make sure that the runtime services are configured and running like described here.\nThe application itself can be executed by using a Visual Studio Launch Config (by pressing F5) or by executing the task SeatAdjuster.\nWhen the runtime services and the application are running, integration tests can be executed locally.\nKubernetes execution (K3D) If you want to execute the integration tests in Kubernetes mode, make sure that K3D is up and running according to the documentation. To ensure that the tests connect to the containers, the following environment variables need to be set:\n MQTT_PORT: 31883 VDB_PORT: 30555  Writing Test Cases To write an integration test, you should check the sample that comes with the template (/test/integration_test.py). To support interacting with the MQTT broker and the Vehicle Data Broker (to get and set values for DataPoints), there are two classes present in Python SDK that will help:\n  MqttClient: this class provides methods for interacting with the MQTT broker. Currently, the following methods are available:\n  publish_and_wait_for_response: publishes the specified payload to the given request topic and waits (till timeout) for a message to the response topic. The payload of the first message that arrives in the response topic will be returned. If the timeout expires before, an empty string (\"\") is returned.\n  publish_and_wait_for_property: publishes the specified payload to the given request topic and waits (till timeout) until the given property value is found in an incoming message to the response topic. The path describes the property location within the response message, the value the property value to look for.\nExample:\n{ \"status\": \"success\", \"result\": { \"responsecode\": 10 } } If the responsecode property should be checked for the value 10, the path would be [\"result\", \"responsecode], property value would be 10. When the requested value has been found in a response message, the payload of that message will be returned. If the timeout expires before receiving a matching message, an empty string (\"\") is returned.\n  This class can be initialized with a given port. If no port is specified, the environment variable MQTT_PORT will be checked. If this is not possible either, the default value of 1883 will be used. It’s recommended to specify no port when initializing that class as it will locally use the default port 1883 and in CI the port set by the environment variable MQTT_PORT. This will prevent a check-in in the wrong port from local development.\n  IntTestHelper: this class provides functionality to interact with the Vehicle Data Broker.\n register_dapoint: registers a new datapoint with given name and type set_..._datapoint: set the given value for the datapoint with the given name (with given type). If the datapoint does not exist, it will be registered.  This class can be initialized with a given port. If no port is specified, the environment variable VDB_PORT will be checked. If this is not possible either, the default value of 55555 will be used. It’s recommended to specify no port when initializing that class as it will locally use the default port 55555 and in CI the port set by the environment variable VDB_PORT which is set. This will prevent a check-in in the wrong port from local development.\n   Please make sure that you don’t check in the test classes with using local ports because then the execution in the CI workflow will fail (as the CI workflow uses Kubernetes execution for running integration tests).\n Running Tests locally Once tests are developed, they can be executed against the running runtime components, either to the local runtime(**Remark Bjoern:** Should we talk here - in analogy to dapr-terminology - of \"self-hosted\". Because \"local\" is used already for distinguishing between execution on local machine vs. CI pripline) or in Kubernetes mode, by using the test runner in Visual Studio Code. The switch to run against the local components or the Kubernetes components is specified by the port. Local ports for Mosquitto and Vehicle Data Broker are 1883/55555. In Kubernetes mode, the ports would be the locally exposed ports 31883/30555. If using the Kubernetes ports, the tests will be executed against the runtime components/application that run in containers within the Kubernetes cluster.\nRunning Tests in CI pipeline The tests will be discovered and executed automatically in the CI pipeline. The job Run Integration Tests contains all steps to setup and execute tests in Kubernetes mode. The results are published as test results to the workflow.\nCommon Tasks Run test in local mode  Make sure that the tasks for the runtime components are running (by checking the terminal view). Make sure that your application is running (via Debugger or task). Make sure that you are using the right ports for local execution of runtime components. Run tests from the test runner.  Run tests in Kubernetes mode  Make sure that K3D is up and running (by calling the scripts in the scripts/k3d folder, 01 - 04). Make sure that the tests are using the right ports for Kubernetes execution. Run tests from the test runner.  Update application when running in Kubernetes mode  Re-run the script /scripts/k3d/04_deploy-apps.sh that rebuilds and deploys the application to K3D. Re-run tests from the test runner.  Troubleshooting Check if the services are registered correctly in Dapr  When running in local mode, call dapr dashboard in a terminal and open the given URL to see the Dapr dashboard in the browser. When running in Kubernetes mode, call dapr dashboard -k in a terminal and open the given URL to see the Dapr dashboard in the browser.  Troubleshoot IntTestHelper  Make sure that the Vehicle Data Broker is up and running by checking the task log. Make sure that you are using the right ports for local/Kubernetes execution. Make sure that you installed the correct version of the SDK (SDV-package).  Troubleshoot Mosquitto (MQTT Broker)  Make sure that the Mosquitto up and running by checking the task log. Make sure that you are using the right ports for local/Kubernetes execution. Use VsMqtt extension to connect to MQTT broker (localhost:1883 (local) or localhost:31883 (Kubernetes)) to monitor topics in MQTT broker.  ","categories":"","description":"Learn how to test that a Vehicle App together with the Vehicle Data Broker and potentially other dependant Vehicle Services or Vehicle Apps runs as expected.\n","excerpt":"Learn how to test that a Vehicle App together with the Vehicle Data …","ref":"/velocitas-docs/docs/tutorials/integration_tests/","tags":"","title":"Vehicle App Integration Testing"},{"body":"This tutorial will show you how to:\n Prepare a Helm chart Deploy your Python Vehicle App to local K3D  Prerequisites  Visual Studio Code with the Python extension installed. For information on how to install extensions on Visual Studio Code, see VS Code Extension Marketplace. Completed the tutorial How to create a vehicle app  Prepare a Helm chart If the Vehicle App has been created from the Python template repository, a sample Helm chart is already available under deploy/SeatAdjusterApp.\nThis will be adapted to deploy a new vehicle app, which is called my_vehicle_app for this walkthrough.\n  Start Visual Studio Code and open the previously created Vehicle App repository.\n  Create a new folder my_vehicle_app under deploy\n  Copy all files from the deploy/SeatAdjusterApp folder to the new folder deploy/my_vehicle_app.\n  Rename the file deploy/my_vehicle_app/helm/templates/seatadjuster.yaml to deploy/my_vehicle_app/helm/templates/my_vehicle_app.yaml\n  Open deploy/my_vehicle_app/helm/Chart.yaml and change the name of the chart to my_vehicle_app and provide a meaningful description.\napiVersion:v2name:my_vehicle_appdescription:Short description for my_vehicle_app# A chart can be either an 'application' or a 'library' chart.## Application charts are a collection of templates that can be packaged into versioned archives# to be deployed.## Library charts provide useful utilities or functions for the chart developer. They're included as# a dependency of application charts to inject those utilities and functions into the rendering# pipeline. Library charts do not define any templates and cannot be deployed as a result.type:application# This is the chart version. This version number should be incremented each time you make changes# to the chart and its templates, including the app version.# Versions are expected to follow Semantic Versioning (https://semver.org/)version:0.1.0# This is the version number of the application being deployed. This version number should be# incremented each time you make changes to the application. Versions are not expected to# follow Semantic Versioning. They should reflect the version the application is using.appVersion:1.16.0  Open deploy/my_vehicle_app/helm/values.yaml and change name, repository and daprAppid to my_vehicle_app. Rename the root node from imageSeatAdjusterApp to imageMyVehicleApp.\nimageMyVehicleApp:name:my_vehicle_apprepository:local/my_vehicle_apppullPolicy:Always# Overrides the image tag whose default is the chart appVersion.tag:\"#SuccessfulExecutionOfReleaseWorkflowUpdatesThisValueToReleaseVersionWithoutV#\"daprAppid:my_vehicle_appdaprPort:50008nameOverride:\"\"fullnameOverride:\"\"  Open deploy/my_vehicle_app/helm/templates/my_vehicle_app.yaml and replace imageSeatAdjusterApp with imageMyVehicleApp:\napiVersion:apps/v1kind:Deploymentmetadata:name:{{.Values.imageMyVehicleApp.name}}labels:app:{{.Values.imageMyVehicleApp.name}}spec:selector:matchLabels:app:{{.Values.imageMyVehicleApp.name}}template:metadata:annotations:dapr.io/enabled:\"true\"dapr.io/app-id:\"{{.Values.imageMyVehicleApp.daprAppid}}\"dapr.io/app-port:\"{{.Values.imageMyVehicleApp.daprPort}}\"dapr.io/log-level:\"debug\"dapr.io/config:\"config\"dapr.io/app-protocol:\"grpc\"labels:app:{{.Values.imageMyVehicleApp.name}}{{- include \"helm.selectorLabels\" . | nindent 8 }}spec:containers:- name:{{.Values.imageMyVehicleApp.name}}image:\"{{ .Values.imageMyVehicleApp.repository }}:{{ .Values.imageMyVehicleApp.tag | default .Chart.AppVersion }}\"imagePullPolicy:{{.Values.imageMyVehicleApp.pullPolicy }}  Rename deploy/my_vehicle_app/deploy_seat-adjuster-app.sh to deploy/my_vehicle_app/deploy-my-vehicle-app.sh and replace all occurences of SeatAdjusterApp with MyVehicleApp and seatservice with my-vehicle-app.\n#!/bin/bash  WORKING_DIR=$(pwd)  if [ -f \"./../../github_token.txt\" ]; then  GITHUB_TOKEN=\"github_token,src=github_token.txt\" else  GITHUB_TOKEN=\"github_token\" fi  if [ -n \"$HTTP_PROXY\" ]; then  echo \"Building image with proxy configuration\"   cd $WORKING_DIR/../../  DOCKER_BUILDKIT=1 docker build \\  -f src/MyVehicleApp/Dockerfile \\  --progress=plain --secret id=$GITHUB_TOKEN \\  -t localhost:12345/my-vehicle-app:local \\  --build-arg HTTP_PROXY=\"$HTTP_PROXY\" \\  --build-arg HTTPS_PROXY=\"$HTTPS_PROXY\" \\  --build-arg FTP_PROXY=\"$FTP_PROXY\" \\  --build-arg ALL_PROXY=\"$ALL_PROXY\" \\  --build-arg NO_PROXY=\"$NO_PROXY\" . --no-cache  docker push localhost:12345/my-vehicle-app:local   cd $WORKING_DIR else  echo \"Building image without proxy configuration\"  # Build, push vehicleapi image - NO PROXY   cd $WORKING_DIR/../../  DOCKER_BUILDKIT=1 docker build -f src/MyVehicleApp/Dockerfile --progress=plain --secret id=$GITHUB_TOKEN -t localhost:12345/my-vehicle-app:local . --no-cache  docker push localhost:12345/my-vehicle-app:local   cd $WORKING_DIR fi  helm uninstall vapp-chart --wait  # Deploy in Kubernetes helm install vapp-chart ./helm --values ../runtime/k3d/values.yml --wait --timeout 60s --debug   At this point, the Helm chart and the sh-script are ready to use and folder structure under deploy/my_vehicle_app should look like this:\ndeploy ├── my_vehicle_app │ └── helm │ └── templates │ └── _helpers.tpl │ └── my_vehicle_app.yaml │────────── .helmignore │────────── Chart.yaml │────────── values.yaml └────── deploy-my-vehicle-app.sh Deploy your Python Vehicle App to local K3D Prerequisites  A local K3D installation must be available. For how to setup K3D, check out this tutorial.  After the Helm chart has been prepared, you can deploy it to local K3D.\n Execute the script deploy/my_vehicle_app/deploy-my-vehicle-app.sh.  This script builds the local source code of the application into a container, pushes that container to the local cluster registry and deploys the app via a helm chart to the K3D cluster. Rerun this script after you have changed the source code of your application to re-deploy with the latest changes.\nNext steps  Release your Vehicle App  ","categories":"","description":"Learn how to prepare a Helm chart for the deployment of a Python Vehicle App.\n","excerpt":"Learn how to prepare a Helm chart for the deployment of a Python …","ref":"/velocitas-docs/docs/tutorials/tutorial_how_to_deploy_a_vehicle_app_with_helm/","tags":"","title":"Vehicle App Deployment with Helm"},{"body":"","categories":"","description":"Learn how to get started with Eclipse Velocity™, including setting up the development enviroment, creating a Vehicle Model as well as developing, testing and deploying a Vehicle App.\n","excerpt":"Learn how to get started with Eclipse Velocity™, including setting up …","ref":"/velocitas-docs/docs/tutorials/","tags":"","title":"Tutorials"},{"body":"Introduction The Vehicle Abstraction Layer (VAL) is a reference implementation of an abstraction layer that allows Vehicle applications to interact with signals and services in the vehicle. It currently consists of a data broker, a CAN feeder and a set of example services. More elaborate or completely differing implementations are the target of particular derived projects.\nArchitecture The image below shows the main components of the Vehicle Abstraction Layer (VAL) and its relation to the Velocitas Development Model.\nOverview of the vehicle abstraction layer architecture   Vehicle Data Broker The Vehicle Data Broker is a gRPC service acting as a broker of vehicle data / data points / signals. It provides central access to vehicle data points arranged in a - preferably standardized - vehicle data model like the COVESA Vehicle Signal Specification (VSS) or others. It is implemented in Rust, can run in a container and provides services to get datapoints, update datapoints and for subscribing to datapoints. Filter- and rule-based subscriptions of datapoints can be used to reduce the number of updates sent to the subscriber.\nData Feeders Conceptually, a data feeder is a provider of a certain set of data points to the data broker. The source of the contents of the data points provided is specific to the respective feeder.\nAs of today, the Vehicle Abstraction Layer contains a generic CAN feeder implemented in Python, which reads data from a CAN bus based on specifications in a e.g., CAN network description file. The feeder then uses a mapping file and data point metadata to convert the source data to data points and injects them into the Vehicle Data Broker using the Vehicle Data Broker gRPC interface. The feeder automatically reconnects to the data broker in the event that the connection is lost.\nVehicle Services A vehicle service offers a gRPC interface for interacting with underlying services. It can provide service interfaces to control actuators or to trigger (complex) actions, or provide interfaces to get data. It communicates with the Hardware Abstraction to execute the underlying services, but may also interact with the Vehicle Data Broker.\nAs of today, the Vehicle Abstraction Layer contains one example service to control a seat. It is implemented in C++ and uses the CAN feeder to control a seat in the vehicle.\nHardware Abstraction Data feeders rely on hardware abstraction. Hardware abstraction project/platform specific. The reference implementation relies on [SocketCAN](https://github.com/eclipse/kuksa.val/tree/master/kuksa_feeders) and vxcan. The hardware abstraction may offer replaying (e.g., CAN) data from a file (can dump file) when the respective data source (e.g., CAN) is not available.\nInformation Flow The vehicle abstraction layer offers an information flow between vehicle networks and vehicle services. The data that can flow is ultimately limited to the data available through the Hardware Abstraction, which is platform/project-specific. Which data can actually be sent or consumed is controlled by DBC and Mapping files. Services (like the seat service) define which CAN signals they listen to and which CAN signals they send themselves, see documentation The Vehicle Data Broker offers read/write/subscribe using MQTT. The VSS signals supported are currently limited by a hard coded list.\nAdditional information on how data privacy is managed can be found in the Vehicle Abstraction Layer repository\nData flow when a Vehicle Application uses the Vehicle Data Broker. Architectural representation of the vehicle data broker data flow   Data flow when a Vehicle Application uses a Vehicle Service. Architectural representation of the vehicle service data flow   Source Code Source code and build instructions are available in the kuksa.val repository.\nGuidelines  Please see the vehicle service guidelines for information on how to implement a Vehicle Service. Please see the interface guideline for best practices on how to specify a gRPC interface.  ","categories":"","description":"","excerpt":"Introduction The Vehicle Abstraction Layer (VAL) is a reference …","ref":"/velocitas-docs/docs/reference/val/","tags":"","title":"Vehicle Abstraction Layer (VAL)"},{"body":"","categories":"","description":"","excerpt":"","ref":"/velocitas-docs/docs/reference/","tags":"","title":"Reference"},{"body":"Thanks for thinking about contributing to Eclipse Velocitas. We really appreciate the time and effort you want to spend helping to improve Eclipse Velocitas.\nHowever, in order to get you started as fast as possible, we need to go through some organizational issues first.\nEclipse Contributor Agreement Before your contribution can be accepted by the project team, contributors must electronically sign the Eclipse Contributor Agreement (ECA).\n http://www.eclipse.org/legal/ECA.php  Commits that are provided by non-committers must have a Signed-off-by field in the footer indicating that the author is aware of the terms by which the contribution has been provided to the project. The non-committer must additionally have an Eclipse Foundation account and must have a signed Eclipse Contributor Agreement (ECA) on file.\nFor more information, please see the Eclipse Committer Handbook: https://www.eclipse.org/projects/handbook/#resources-commit\nMaking Your Changes  Fork the repository on GitHub. Create a new branch for your changes. Make your changes following the code style guide (see Code Style Guide section above). When you create new files, make sure you include a proper license header at the top of the file (see License Header section below). Make sure you include test cases for non-trivial features. Make sure test cases provide sufficient code coverage (see GitHub actions for minimal accepted coverage). Make sure the test suite passes after your changes. Commit your changes into that branch. Use descriptive and meaningful commit messages. Start the first line of the commit message with the issue number and title e.g., [#9865] Add token-based authentication. Squash multiple commits that are related to each other semantically into a single one. Make sure you use the -s flag when committing as explained above. Push your changes to your branch in your forked repository.  Adding Documentation to Hugo  Add the markdown document to the appropriate folder in the path velocitas-docs/hugo/hugo/content. Add the front-matter  ---title:\"title of the file\"date:2022-05-09T13:43:25+05:30--- Additional front matter that can be added –  url : \"specifying a definite url to the file\" weight : 10 (used for ordering your content in lists. Lower weight gets higher precedence.)   The images need to be put in path velocitas-docs/hugo/hugo/static/assests. The image reference should be /assests/image.jpg in the markdown file. (Note: Do not use relative paths or url) In case you are creating a new folder, create _index.md file with the front matter only.  Running Locally  Install hugo version 0.98.0 extended Release v0.98.0 · gohugoio/hugo (github.com) Install Docsy theme in the path velocitas-docs/hugo/hugo/theme –  #Run this command from the root directory of velocitas-docs git clone https://github.com/google/docsy.git hugo/hugo/themes/docsy  Install pre-requisites  cd themes/docsy/userguide/ npm install npm install --save-dev postcss  Run the command hugo server visit localhost:1313 from the velocitas-docs/hugo/hugo directory to see the rendered static site.  Submitting the Changes Submit a pull request via the normal GitHub UI.\nAfter Submitting  Do not use your branch for any other development, otherwise further changes that you make will be visible in the PR.  License Header Please make sure any file you newly create contains a proper license header like this:\n# Copyright (c) \u003cyear\u003e Contributors to the Eclipse Foundation # # See the NOTICE file(s) distributed with this work for additional # information regarding copyright ownership. # # This program and the accompanying materials are made available under the # terms of the Apache License 2.0 which is available at # http://www.apache.org/licenses/LICENSE-2.0 # # SPDX-License-Identifier: Apache-2.0 You should, of course, adapt this header to use the specific mechanism for comments pertaining to the type of file you create.\nImportant\nPlease do not forget to add your name/organization to the /legal/legal/NOTICE.md file’s Copyright Holders section. If this is not the first contribution you make, then simply update the time period contained in the copyright entry to use the year of your first contribution as the lower boundary and the current year as the upper boundary, e.g.,\nCopyright 2017, 2018 ACME Corporation\nBuild  A pipeline run will be triggered on every PR merge. This run will trigger the hugo docs build Hugo v0.98.0 extended is set up for the runner Docsy theme is setup for beautification of static site Then dependencies are installed for the theme Static site is generated and stored in a folder \"public\" The contents of public are committed to gh_pages branch which is exposed to host the GitHub pages  ","categories":"","description":"","excerpt":"Thanks for thinking about contributing to Eclipse Velocitas. We really …","ref":"/velocitas-docs/docs/contribution/","tags":"","title":"Contribution"},{"body":"Background Traditionally, the automotive industry was and still is centered around vehicle hardware and the corresponding hardware development and life-cycle management. Software, however, is gaining more and more importance in vehicle development and over the entire vehicle lifetime. Thus, the vehicle and its value to the customer is increasingly defined by software. This transition towards what are termed as software-defined vehicles changes the way in which we innovate, code, deliver and work together. It is a change across the whole mobility value chain and life-cycle: from development and production to delivery and operations of the vehicle.\nGoal The Eclipse project Velocitas aims to build-up an end-to-end, scalable and modular development toolchain to create containerized in-vehicle applications (Vehicle Apps) that offers a comfortable, fast and efficient development experience to increase the speed of a development team.\nThe DevOps cycle that it followed in the design of the Velocitas programnming model      Category Description     Vehicle App Project Template Quick setup of a Vehicle App project with the help of GitHub templates for the supported programming languages including a sample Vehicle App and GitHub Actions workflow, and comfortable setup of the development environment e.g. in Microsoft Visual Studio Code.   Vehicle App Programming Model Simplify coding and debugging of Vehicle Apps that accessing vehicle data points and modifying vehicle functions using the provided SDK for the different programming languages that delegates to the Vehicle Abstraction Layer.   Vehicle Abstraction Layer Abstracts vehicle make \u0026 model specific properties and capabilities to a common representation. This makes it possible for Vehicle Apps to be portable across different electric and electronic vehicle architectures e.g. the Vehicle Apps do not care whether the seat is controlled via CAN, LIN or some other physical interface.   GitHub Actions Workflow Blueprint Providing ready-to-use GitHub workflows to check the Vehicle App, build images for multi architectures, scan it, execute integration tests and release the Vehicle App to allow the developer to focus on the development of the Vehicle App.   Automated Release Process Providing a release workflow to generate release artifacts and documentation out of the CI workflow results and push it to a container registry to be used by a deployment system   Runtime and Deployment Model Running and deploying Vehicle App as OCI-compliant container to increase the flexibility to support different programming languages and runtimes to accelerate innovation and development.    The repositories of the Eclipse project Velocitas and their relations between each other can be found [here].\nExample Use Case Velocitas contains implementations based on the example use case of adjusting the vehicle seat position to showcase the development toolchain of a comfort function (QM level - non-safety relevant).\nWhat could such a use case look like? Image a carsharing company that wants to offer its customers the functionality that the driver seat automatically moves to the right position, when the driver enters the rented car. The carsharing company knows the driver and has stored the preferred seat position of the driver in its driver profile. The car gets unlocked by the driver and a request for the preferred seat position of the driver will be sent to the vehicle.\nThat’s where your implementation starts. The Seat Adjuster VehicleApp receives the seat position as a MQTT message and triggers a seat adjustment command of the Seat Service that changes the seat position. Of course, the driver of a rented car would like the position, that he may have set himself, to be saved by the carsharing company and used for the next trip. As a result, the Seat Adjuster VehicleApp subscribes to the seat position and receives the new seat position from the Vehicle Data Broker that streams the data from the Seat Service.\nA detailed description of the Seat Adjuster use case can be found here.\nArchitectural representation of the data flow on the example of adjusting the seat position   References  Vehicle Signal Specifications (VSS)  ","categories":"","description":"About Eclipse Velocitas features.\n","excerpt":"About Eclipse Velocitas features.\n","ref":"/velocitas-docs/about/","tags":"","title":"About"},{"body":"Background Traditionally, the automotive industry was and still is centered around vehicle hardware and the corresponding hardware development and life-cycle management. Software, however, is gaining more and more importance in vehicle development and over the entire vehicle lifetime. Thus, the vehicle and its value to the customer is increasingly defined by software. This transition towards what are termed as software-defined vehicles changes the way in which we innovate, code, deliver and work together. It is a change across the whole mobility value chain and life-cycle: from development and production to delivery and operations of the vehicle.\nGoal The Eclipse project Velocitas aims to build-up an end-to-end, scalable and modular development toolchain to create containerized in-vehicle applications (Vehicle Apps) that offers a comfortable, fast and efficient development experience to increase the speed of a development team.\nThe DevOps cycle that it followed in the design of the Velocitas programnming model      Category Description     Vehicle App Project Template Quick setup of a Vehicle App project with the help of GitHub templates for the supported programming languages including a sample Vehicle App and GitHub Actions workflow, and comfortable setup of the development environment e.g. in Microsoft Visual Studio Code.   Vehicle App Programming Model Simplify coding and debugging of Vehicle Apps that accessing vehicle data points and modifying vehicle functions using the provided SDK for the different programming languages that delegates to the Vehicle Abstraction Layer.   Vehicle Abstraction Layer Abstracts vehicle make \u0026 model specific properties and capabilities to a common representation. This makes it possible for Vehicle Apps to be portable across different electric and electronic vehicle architectures e.g. the Vehicle Apps do not care whether the seat is controlled via CAN, LIN or some other physical interface.   GitHub Actions Workflow Blueprint Providing ready-to-use GitHub workflows to check the Vehicle App, build images for multi architectures, scan it, execute integration tests and release the Vehicle App to allow the developer to focus on the development of the Vehicle App.   Automated Release Process Providing a release workflow to generate release artifacts and documentation out of the CI workflow results and push it to a container registry to be used by a deployment system   Runtime and Deployment Model Running and deploying Vehicle App as OCI-compliant container to increase the flexibility to support different programming languages and runtimes to accelerate innovation and development.    The repositories of the Eclipse project Velocitas and their relations between each other can be found [here].\nExample Use Case Velocitas contains implementations based on the example use case of adjusting the vehicle seat position to showcase the development toolchain of a comfort function (QM level - non-safety relevant).\nWhat could such a use case look like? Image a carsharing company that wants to offer its customers the functionality that the driver seat automatically moves to the right position, when the driver enters the rented car. The carsharing company knows the driver and has stored the preferred seat position of the driver in its driver profile. The car gets unlocked by the driver and a request for the preferred seat position of the driver will be sent to the vehicle.\nThat’s where your implementation starts. The Seat Adjuster VehicleApp receives the seat position as a MQTT message and triggers a seat adjustment command of the Seat Service that changes the seat position. Of course, the driver of a rented car would like the position, that he may have set himself, to be saved by the carsharing company and used for the next trip. As a result, the Seat Adjuster VehicleApp subscribes to the seat position and receives the new seat position from the Vehicle Data Broker that streams the data from the Seat Service.\nA detailed description of the Seat Adjuster use case can be found here.\nArchitectural representation of the data flow on the example of adjusting the seat position   Quickstart tutorials  Setup and Explore Development Enviroment Developing a Vehicle Model in Python Developing a Vehicle App in Python Run and develop integration tests for Vehicle Apps  References  Vehicle Signal Specifications (VSS)  Community  GitHub Issues Mailing List Contribution  ","categories":"","description":"","excerpt":"Background Traditionally, the automotive industry was and still is …","ref":"/velocitas-docs/docs/","tags":"","title":"Documentation"},{"body":"GRPC Interface Style Guide This document provides a style guide for .proto files. By following these conventions, you’ll make your protocol buffer message definitions and their corresponding classes consistent and easy to read. Unless otherwise indicated, this style guide is based on the style guide from google protocol-buffers style under Apache 2.0 License \u0026 Creative Commons Attribution 4.0 License.\nNote that protocol buffer style can evolve over time, so it is likely that you will see .proto files written in different conventions or styles. Please respect the existing style when you modify these files. Consistency is key. However, it is best to adopt the current best style when you are creating a new .proto file.\nStandard file formatting  Keep the line length to 80 characters. Use an indent of 2 spaces. Prefer the use of double quotes for strings.  File structure Files should be named lower_snake_case.proto\nAll files should be ordered in the following manner:\n License header File overview Syntax Package Imports (sorted) File options Everything else  Directory Structure Files should be stored in a directory structure that matches their package sub-names. All files in a given directory should be in the same package. Below is an example based on the proto files in the kuksa.val repository.\n| proto/ | └── sdv | └── databroker | └── v1 // package sdv.databroker.broker.v1 | ├── broker.proto // service Broker in sdv.databroker.broker.v1 | ├── collector.proto // service Collector in sdv.databroker.broker.v1 | └── types.proto // type definition and import of in sdv.databroker.broker.v1 The proposed structure shown above is adapted from Uber Protobuf Style Guide V2 under MIT License.\nPackages Package names should be in lowercase. Package names should have unique names based on the project name, and possibly based on the path of the file containing the protocol buffer type definitions.\nMessage and field names Use PascalCase (CamelCase with an initial capital) for message names – for example, SongServerRequest. Use underscore_separated_names for field names (including oneof field and extension names) – for example, song_name.\nmessage SongServerRequest {  optional string song_name = 1; } Using this naming convention for field names gives you accessors like the following:\nC++:\nconst string\u0026 song_name() { ... } void set_song_name(const string\u0026 x) { ... } If your field name contains a number, the number should appear after the letter instead of after the underscore. For example, use song_name1 instead of song_name_1 Repeated fields\nUse pluralized names for repeated fields.\nrepeated string keys = 1;...repeated MyMessage accounts = 17;Enums Use PascalCase (with an initial capital) for enum type names and CAPITALS_WITH_UNDERSCORES for value names:\nenum FooBar {  FOO_BAR_UNSPECIFIED = 0;  FOO_BAR_FIRST_VALUE = 1;  FOO_BAR_SECOND_VALUE = 2; } Each enum value should end with a semicolon, not a comma. The zero value enum should have the suffix UNSPECIFIED.\n###Services\nIf your .proto defines an RPC service, you should use PascalCase (with an initial capital) for both the service name and any RPC method names:\nservice FooService { rpc GetSomething(GetSomethingRequest) returns (GetSomethingResponse); rpc ListSomething(ListSomethingRequest) returns (ListSomethingResponse);}GRPC Interface Versioning All API interfaces must provide a major version number, which is encoded at the end of the protobuf package. If an API introduces a breaking change, such as removing or renaming a field, it must increment its API version number to ensure that existing user code does not suddenly break. Note: The use of the term “major version number” above is taken from semantic versioning. However, unlike in traditional semantic versioning, APIs must not expose minor or patch version numbers. For example, APIs use v1, not v1.0, v1.1, or v1.4.2. From a user’s perspective, minor versions are updated in place, and users receive new functionality without migration.\nA new major version of an API must not depend on a previous major version of the same API. An API may depend on other APIs, with an expectation that the caller understands the dependency and stability risk associated with those APIs. In this scenario, a stable API version must only depend on stable versions of other APIs.\nDifferent versions of the same API should preferably be able to work at the same time within a single client application for a reasonable transition period. This time period allows the client to transition smoothly to the newer version. An older version must go through a reasonable, well-communicated deprecation period before being shut down.\nFor releases that have alpha or beta stability, APIs must append the stability level after the major version number in the protobuf package.\nRelease-based versioning An individual release is an alpha or beta release that is expected to be available for a limited time period before its functionality is incorporated into the stable channel, after which the individual release will be shut down. When using release-based versioning strategy, an API may have any number of individual releases at each stability level.\nAlpha and beta releases must have their stability level appended to the version, followed by an incrementing release number. For example, v1beta1 or v1alpha5. APIs should document the chronological order of these versions in their documentation (such as comments). Each alpha or beta release may be updated in place with backwards-compatible changes. For beta releases, backwards-incompatible updates should be made by incrementing the release number and publishing a new release with the change. For example, if the current version is v1beta1, then v1beta2 is released next.\nAdapted from google release-based_versioning under Apache 2.0 License \u0026 Creative Commons Attribution 4.0 License\nBackwards compatibility The gRPC protocol is designed to support services that change over time. Generally, additions to gRPC services and methods are non-breaking. Non-breaking changes allow existing clients to continue working without changes. Changing or deleting gRPC services are breaking changes. When gRPC services have breaking changes, clients using that service have to be updated and redeployed.\nMaking non-breaking changes to a service has a number of benefits:\n Existing clients continue to run. Avoids work involved with notifying clients of breaking changes, and updating them. Only one version of the service needs to be documented and maintained.  Non-breaking changes These changes are non-breaking at a gRPC protocol level and binary level.\n Adding a new service Adding a new method to a service Adding a field to a request message - Fields added to a request message are deserialized with the default value on the server when not set. To be a non-breaking change, the service must succeed when the new field isn’t set by older clients. Adding a field to a response message - Fields added to a response message are deserialized into the message’s unknown fields collection on the client. Adding a value to an enum - Enums are serialized as a numeric value. New enum values are deserialized on the client to the enum value without an enum name. To be a non-breaking change, older clients must run correctly when receiving the new enum value.  Binary breaking changes The following changes are non-breaking at a gRPC protocol level, but the client needs to be updated if it upgrades to the latest .proto contract. Binary compatibility is important if you plan to publish a gRPC library.\n Removing a field - Values from a removed field are deserialized to a message’s unknown fields. This isn’t a gRPC protocol breaking change, but the client needs to be updated if it upgrades to the latest contract. It’s important that a removed field number isn’t accidentally reused in the future. To ensure this doesn’t happen, specify deleted field numbers and names on the message using Protobuf’s reserved keyword. Renaming a message - Message names aren’t typically sent on the network, so this isn’t a gRPC protocol breaking change. The client will need to be updated if it upgrades to the latest contract. One situation where message names are sent on the network is with Any fields, when the message name is used to identify the message type. Nesting or unnesting a message - Message types can be nested. Nesting or unnesting a message changes its message name. Changing how a message type is nested has the same impact on compatibility as renaming.  Protocol breaking changes The following items are protocol and binary breaking changes:\n Renaming a field - With Protobuf content, the field names are only used in generated code. The field number is used to identify fields on the network. Renaming a field isn’t a protocol breaking change for Protobuf. However, if a server is using JSON content, then renaming a field is a breaking change. Changing a field data type - Changing a field’s data type to an incompatible type will cause errors when deserializing the message. Even if the new data type is compatible, it’s likely the client needs to be updated to support the new type if it upgrades to the latest contract. Changing a field number - With Protobuf payloads, the field number is used to identify fields on the network. Renaming a package, service or method - gRPC uses the package name, service name, and method name to build the URL. The client gets an UNIMPLEMENTED status from the server. Removing a service or method - The client gets an UNIMPLEMENTED status from the server when calling the removed method.  Behavior breaking changes When making non-breaking changes, you must also consider whether older clients can continue working with the new service behavior. For example, adding a new field to a request message:\n Isn’t a protocol breaking change. Returning an error status on the server if the new field isn’t set makes it a breaking change for old clients.  Behavior compatibility is determined by your app-specific code.\nAdapted from Versioning gRPC services under Creative Commons Attribution 4.0 License\nError Handling gRPC error handling In gRPC, a large set of error codes has been defined As a general rule, SDV should use relevant gRPC error codes, as described in this thread\n return grpc::Status(grpc::StatusCode::NOT_FOUND, \"error details here\"); Available constructor:\n grpc::Status::Status ( StatusCode code,  const std::string \u0026 error_message,  const std::string \u0026 error_details The framework for drafting error messages could be useful as a later improvement. This could e.g., be used to specify which unit created the error message and to assure the same structure on all messages. The latter two may e.g., depend on debug settings, e.g., error details only in debug-builds to avoid leaks of sensitive information. A global function like below or similar could handle that and also possibly convert between internal error codes and gRPC codes.\n grpc::Status status = CreateStatusMessage(PERMISSION_DENIED,\"DataBroker\",\"Rule access rights violated\"); VSC error handling VSC recently added errors to the example service.\n methods:  - name: move  description: |  Set the desired seat position  in:  - name: seat  description: |  The desired seat position  datatype: seat_t   error:  datatype: .stdvsc.error_t  range: $ in_set(\"ok\", \"completed\", \"in_progress\", \"interrupted\") The errors come from a standardized error list, and for each method in VSC, a range clause can be used to specify which errors from that list that are applicable.\nIt is in VSC explicitly specified that:\nTransport-layer issues arising from interrupted communication, services going down, etc, are handled on a language-binding level where each language library implements its own way of detecting, reporting, and recovering from network-related errors.\nThis means that VSC error messages intentionally cover a smaller subset than gRPC error messages. Unlike gRPC, there is currently no detailed documentation in VCS on when individual error codes shall be used, which could cause problems as some error codes are similar.\nSDV error handling for gRPC interfaces (e.g., VAL vehicles services)  Use gRPC error codes as base Document in proto files (as comments) which error codes that the service implementation can emit and the meaning of them. (Errors that only are emitted by the gRPC framework do not need to be listed.) Do not - unless there are special reasons - add explicit error/status fields to rpc return messages. Additional error information can be given by free text fields in gRPC error codes. Note, however, that sensitive information like Given password ABCD does not match expected password EFGH should not be passed in an unprotected/unencrypted manner.  SDV handling of gRPC error codes The table below gives error code guidelines for each gRPC on:\n If it is relevant for a client to retry the call or not when receiving the error code. Retry is only relevant if the error is of a temporary nature. Which VSC error code matches the respective gRPC error code When to use the error code when implementing a service.    gRPC error code Retry Relevant? Corresponding VSC error codes Recommended SDV usage   OK No ok, completed, in_progress Mandatory error code if operation succeeded. Shall never be used if operation failed.   CANCELLED No interrupted No explicit use case on server side in SDV identified   UNKNOWN No other To be used in default-statements when converting errors from e.g., Broker-errors to SDV/gRPC errors   INVALID_ARGUMENT No invalid_argument E.g., Rule syntax with errors   DEADLINE_EXCEEDED Yes expired Only applicable for asynchronous services, i.e. services which wait for completion before the result is returned. The behavior if a VSC operation cannot finish within expected time must be defined. Two options exist. One is to return this error after e.g., X seconds. Another is that the server never gives up, but rather waits for the client to cancel the operation.   NOT_FOUND No not_found Long term situation that likely not will change in the near future.  Example: SDV can not find the specified resource (e.g., no path to get data for specified seat)    ALREADY_EXISTS No other No explicit use case on server side in SDV identified   PERMISSION_DENIED No permission_denied Operation rejected due to permission denied   RESOURCE_EXHAUSTED Yes no_resource, busy Possibly if e.g., malloc fails or similar errors.   FAILED_PRECONDITION Yes incorrect_state Could be returned if e.g., operation is rejected due to safety reasons. (E.g., vehicle moving)   ABORTED Yes lost_arbitration Could e.g., be returned if service does not support concurrent requests, and there is already either a related operation ongoing or the operation is aborted due to a newer request received. Could also be used if an operation is aborted on user/driver request, e.g., physical button in vehicle pressed.   OUT_OF_RANGE No invalid_argument E.g., Arguments out of range   UNIMPLEMENTED No not_supported To be used if certain use-cases of the service are not implemented, e.g., if recline cannot be adjusted   INTERNAL No other Internal errors, like exceptions, unexpected null pointers and similar   UNAVAILABLE Yes no_service To be used if the service is temporarily unavailable, e.g., during system startup.   DATA_LOSS No other No explicit use case identified on server side in SDV. Out of scope of VSC.   UNAUTHENTICATED No other No explicit use case identified on server side in SDV. Out of scope of VSC.   N/A N/A null VSC error not applicable if using gRPC as gRPC always return an error code   As can be seen in the table above, there is not always a 1:1 mapping between VSC errors and gRPC errors. Parts of this need to be sorted out in VSC context, e.g., difference between ok and completed.\nProposed handling when implementing service defined in VSC The starting approach when implementing a service defined in VSC in a framework using gRPC errors is to only use gRPC errors that correspond to defined VSC errors. If a VSC method e.g., specifies only ok and incorrect_state as error codes, then an implementation using gRPC shall, if possible, only use the gRPC error codes OK and FAILED_PRECONDITION. If additional gRPC errors are relevant, then it shall be investigated whether or not the specified VSC list of errors can be extended.\nComparison on actual error code usage The current list of error codes in VSC does not cover all error messages that SDV can return. Extensions are needed, but can be covered by existing VSC error codes. The existing VSC definitions shall preferably be extended with comments so that the meaning of the different error codes in this particular context are clarified.\n  VSC Method Currently defined VSC errors Used gRPC errors Proposed VSC changes   move \"ok\", \"completed\", \"in_progress\", \"interrupted\" OK, OUT_OF_RANGE, INVALID_ARGUMENT, INTERNAL Add invalid_argument, other. Difference between ok and completed to be clarified. When/how is in_progress to be used? Possibly add \"not_found\" as used by other methods.   move_component \"ok\", \"not_found\", \"busy\" OK, OUT_OF_RANGE, NOT_FOUND, INVALID_ARGUMENT, INTERNAL Add invalid_argument, other.    current_position \"ok\", \"not_found\" OK, OUT_OF_RANGE Add invalid_argument, check VSC difference between not_found and invalid_argument     Other references  Pattern for rich error handling in gRPC Advanced gRPC Error Usage  ","categories":"","description":"","excerpt":"GRPC Interface Style Guide This document provides a style guide for …","ref":"/velocitas-docs/docs/reference/val/interface_guideline/","tags":"","title":"Interface Design Guideline"},{"body":" How to create a vehicle service  Motivation Overview Define a service interface  Semantic model Interface technology and programming languages Interface guideline Error codes   Implement a vehicle service  Examples Responsibility Connection status   Add Dapr support to the vehicle service  Metadata Connection status with Dapr   Interaction with the vehicle data broker (optional)    How to create a vehicle service Motivation Vehicle services abstract complex behavior of the vehicle. They abstract the differences in electric and electronic architecture of vehicles from different brands and models to a common interface, which is aligned to a harmonized semantic model. A Vehicle App developer interacts with the vehicle abstraction layer components via the SDK. The SDK and the VAL components are aligned via the interface description, which is derived from the semantic model.\nOverview Following steps are needed to create a vehicle service:\n Define a service interface Implement the service Add support for Dapr middleware (optional) Implement simulation (optional) Interaction with the vehicle data broker  Define a service interface Semantic model The service interface of the vehicle service which abstracts the vehicle behavior, should be aligned to the semantic model. The VEHICLE SERVICE CATALOG can be used as the semantic model for a service call.\nInterface technology and programming languages The interface technology used for remote procedure calls is gGRPC. The methods and datatypes are first defined in a *.proto file, which is then used to generate client and server stubs/skeletons in different languages.\nHow to use the interface and generate code can be read e.g., here: Basics tutorial for gRPC in C++ or Basics tutorial for gRPC in Python.\nInterface guideline The gRPC interface guideline provides you with help on how to specify the service interface.\nError codes The error codes and recommended usage is described in Error Handling. The errors implemented should be described in the gRPC interface description files (*.proto).\nImplement a vehicle service Examples For help on how to implement the vehicle service, see the example seat service or the gRPC examples in different languages.\nResponsibility A vehicle service …\n Can provide service interfaces to control actuators or to trigger (complex) actions Can provide service interfaces to get data Uses service interfaces to register and publish data to the data broker Reconnects to the data broker in case the connection is lost Uses the service interface of the data broker via Dapr, if deployed Communicates with a vehicle network, which is connected to real hardware (e.g., CAN interface) Communicates with a virtual interface (e.g., CAN interface) (Optional) Provides a simulation mode to run without a network interface  A vehicle service implementation ..\n might be implemented vehicle- or project-specific  Connection status To be able to detect connectivity problems users of a gRPC service, e.g., for feeding data to the data broker, shall preferably monitor the gRPC connection state, see: gRPC Connectivity Semantics and API . This can be used to report or log errors if the connection behaves differently than expected.\nAdd Dapr support to the vehicle service You can use the gRPC proxying feature of Dapr, which allows you to use custom *.proto files/ interfaces instead of the predefined Dapr gRPC interfaces. More can be read at How-To: Invoke services using gRPC.\nTo support Dapr within your vehicle service application ..\n the gRPC metadata dapr-app-id of the server needs to be specified in the call the used gRPC port should be configurable at least via the environment variable, use DAPR_GRPC_PORT.  A full reference to the Dapr environment variables can be found here.\nMetadata To call the methods of a gRPC server (e.g. register data points on the data broker) via Dapr the gRPC calls need to be extended with metadata.\nWe recommend that you read the dapr-app-id of the gRPC server either from the command line parameter, environment variable of configuration file instead of hardcoding it, see for Python:\n grpc_metadata = (  (\"dapr-app-id\", os.environ.get(\"VEHICLEDATABROKER_DAPR_APP_ID\")),  )   channel = grpc.insecure_channel(databroker_address)  channel.subscribe( ... )  self._provider = databroker.Provider(channel, grpc_metadata) This makes it possible to keep the resulting containerized application independent of the configuration and avoid unnecessary rebuilds.\nConnection status with Dapr In a Dapr environment, evaluating the gRPC connectivity state as described in connection status is not sufficient. Since the vehicle service communicates via gRPC with the Dapr sidecar application instead with the Dapr server directly, the gRPC communication state is also related to the Dapr side car instead of the server. Additional measures need to be taken to check if the “real” server is available. Dapr gRPC proxying is only allowed AFTER the Dapr sidecar is fully initialized. If an app port has been specified when running the Dapr sidecar, the sidecar verifies that the service is listening on the port first as part of the initialization.\nThe following sequence in vehicle services is recommended:\n Create a gRPC Server and listen Wait for the sidecar (e.g., poll health endpoint or sleep ) Execute gRPC proxying calls (e.g., against Vehicle Data Broker)  Example: A callback for the connectivity state in conjugation with retry to call the server:\n channel = grpc.insecure_channel(databroker_address)  channel.subscribe(  lambda connectivity: self.on_broker_connectivity_change(connectivity),  try_to_connect=False,  )   ...   def on_broker_connectivity_change(self, connectivity):  if (  connectivity == grpc.ChannelConnectivity.READY  or connectivity == grpc.ChannelConnectivity.IDLE  ):  ## Can change between READY and IDLE. Only act if coming from  ## unconnected state  if not self._connected:  log.info(\"Connected to data broker\")  try:  self._register_datapoints()  self._registered = True  except Exception:  log.error(\"Failed to register datapoints\", exc_info=True)  self._connected = True  else:  if self._connected:  log.info(\"Disconnected from data broker\")  else:  if connectivity == grpc.ChannelConnectivity.CONNECTING:  log.info(\"Trying to connect to data broker\")  self._connected = False  self._registered = False If the Dapr side car is ready to forward, communication can be checked with the GRPC Health Checking Protocol , see also Python gRPC Health Checking.\nInteraction with the vehicle data broker (optional) Use the interface description of the vehicle data broker (*.proto files) to publish data to the vehicle data broker. In the collector.proto you find methods to\n register datapoints RegisterDatapoints, afterwards you can feed data via single calls UpdateDatapoints or in a stream manner StreamDatapoints  See the *.proto files for a detailed description.\n","categories":"","description":"","excerpt":" How to create a vehicle service  Motivation Overview Define a service …","ref":"/velocitas-docs/docs/reference/val/vehicle_service/","tags":"","title":"Vehicle Service"},{"body":"The example of the seat adjuster provides the option of requesting the new seat position and publishing the current seat position to the customer and demonstrating so the content of the Eclipse project Velocitas in this way. The following chapter describes the data flow for the use cases.\nRequesting new seat position Architectural diagram of the seat adjuster example use case    The Customer requests the change of the seat position as MQTT message on the topic seatadjuster/setPosition/request with the payload: {\"requestId\": \"xyz\", \"position\": 300}  The Seat Adjuster Vehicle App that has subscribed to this topic, receives the request to change the seat position as a MQTT message. The Seat Adjuster Vehicle App gets the current vehicle speed from the data broker, which is fed by the Generic CAN Feeder. With the support of the Vehicle App SDK, the Seat Adjuster Vehicle App triggers a seat adjustment command of the Seat Service via gRPC in the event that the speed is equal to zero. Hint: This is a helpful convenience check but not a safety check. The Seat Service moves the seat to the new position via CAN messages. The Seat Service returns OK or an error code as grpc status to the Seat Adjuster Vehicle App. If everything went well, the Seat Adjuster Vehicle App returns a success message for the topic seatadjuster/setPosition/response with the payload: {\"requestId\": \"xyz\", \"status\": 0 } Otherwise, an error message will be returned: {requestId\": \"xyz\", \"status\": 1, \"message\" = \"\u003cerror message\u003e\" }  This success or error message will be returned to the Customer.  Publishing current seat position Architectural diagram of the data flow for publishing a new seat position    If the seat position will be changed by the driver, the new seat position will be sent to the Seat Service via CAN. The Seat Service streams the seat position via gRPC to the Vehicle Data Broker since it was registered beforehand. The Seat Adjuster Vehicle App that subscribed to the seat position receives the new seat position from the Vehicle Data Broker as a result. The Seat Adjuster Vehicle App publishes this on topic seatadjuster/currentPosition with the payload: {\"position\": 350}  The Customer who has subscribed to this topic retrieves the new seat position and can store this position to use it for the next trip.  ","categories":"","description":"","excerpt":"The example of the seat adjuster provides the option of requesting the …","ref":"/velocitas-docs/docs/reference/seat_adjuster_use_case/","tags":"","title":"Example Use Case"},{"body":"   Repository Description     vehicle-app-python-template GitHub Template repository containing an exemplary Vehicle App that uses an exemplary SDK to provide access to vehicle data points and methods. The sample SDK extends the sdv-vehicle-app-python-sdk. In addition the template repository contains the development environment for Visual Studio Code for a Vehicle App as well as the CI/CD workflows that can be used as blueprint for your own Vehicle App written in Python.   vehicle-app-python-sdk Provides basis functionality to write an SDK to allow access to vehicle data points and method. This includes publishing \u0026 subscribe messaging, talent abstraction, vehicle data model ontology and function-based query \u0026 rule support.   swdc-os-vehicleapi Provides a vehicle abstraction layer (val) including Vehicle Data Broker, an exemplary CAN Data Feeder as well as a Seat Vehicle Service. The Vehicle Data Broker provides data points available in the vehicle to the Vehicle Apps semantically aligned to the Vehicle Signal Specification (VSS). The CAN Data Feeder is an exemplary implementation that reads in data from the vehicle’s CAN bus, transforms it according to the VSS and feeds it into the Data Broker. The Seat Vehicle Service is an exemplary implementation that illustrates how to interact with in-vehicle components and services via an unified access that is semantically described in the Vehicle Service Catalog (VSC).   release-documentation-action GitHub Action to generate a release documentation from the CI workflow output by rendering it to markdown files so that this can be easily published with GitHub Pages.   license-check GitHub Action to collect the licenses of the used components and can be configured to fail with an error message on invalid licenses.   vehicle-model-generator Provides basic functionality to create a vehicle model from the given vspec specification for the target programming language.    ","categories":"","description":"","excerpt":"   Repository Description     vehicle-app-python-template GitHub …","ref":"/velocitas-docs/docs/reference/repository_overview/","tags":"","title":"Repository Overview"},{"body":"Besides local execution, another way of running the runtime components is to deploy them as containers in a Kubernetes control plane (like K3D). To create a K3D instance, we provide Visual Studio Code Tasks, a feature of Visual Studio Code. Additional information on tasks can be found here.\nQuick Start: Each step has a task that is defined in .vscode/tasks.json:\n Core tasks (dependent on each other in the given order):  K3D - Install prerequisites: Install prerequisite components K3D, Helm, KubeCTL and Dapr without configuring them. K3D - Configure control plane: Creates a local container registry used by K3D as well as an K3D cluster with Dapr enabled. K3D - Deploy runtime: Deploys the runtime components (like Vehicle Data Broker, Seat Service, …) within the K3D cluster. K3D - Build SeatAdjusterApp: Builds the SeatAdjusterApp and pushes it to the local K3D registry. K3D - Deploy SeatAdjusterApp: Builds and deploys the SeatAdjusterApp via Helm to the K3D cluster.    Each task has the required dependencies defined. If you want to run the runtime in K3D, the task K3D - Deploy SeatAdjusterApp will create and configure everything. So it’s enough to run that task.\n Optional helper tasks:  K3D - Deploy SeatAdjusterApp (without rebuild): Deploys the SeatAdjusterApp via Helm to the K3D cluster (without rebuilding it). That requires, that the task K3D - Build SeatAdjusterApp has been executed once before. K3D - Install tooling: Installs tooling for local debugging (K9s) K3D - Uninstall runtime: Uninstalls the runtime components from the K3D cluster (without deleting the cluster). K3D - Reset control plane: Deletes the K3D cluster and the registry with all deployed pods/services.    K3D is configured so that Mosquitto and the Vehicle Data Broker can be reached from outside the container over the ports 31883 (Mosquitto) and 30555(Vehicle Data Broker). The test runner, that is running outside of the cluster, can interact with these services over those ports.\nTo check the status of your K3D instance (running pods, containers, logs, …) you can either use the kubectl utility or start K9s (after running the task K3D - Install tooling once) in a terminal window to have a UI for interacting with the cluster.\nRun as Bundle: To orchestrate these tasks, a task called K3D - Deploy SeatAdjusterApp is available. This task runs the other tasks in the correct order. You can run this task by clicking F1 and choose Tasks: Run task, then select K3D - Deploy SeatAdjusterApp.\nTasks Management: Visual Studio Code offers various other commands concerning tasks like Start/Terminate/Restart/… You can access them by pressing F1 and typing task. A list with available task commands will appear.\nLogging: Running tasks appear in the Terminals View of Visual Studio Code. From there, you can see the logs of each running task.\nUploading files to persistentVolume Some applications (e.g. FeederCAN) might make it necessary to load custom files from mounted volume. For that reason, persistentVolume is created in k3d cluster. All the files that are located in deploy/runtime/k3d/volume will be uploaded to the k3d cluster dynamically. In order to mount files to the directory that is accessible by the application, please refer to the deployment configuration file: deploy/runtime/k3d/helm/templates/bash.yaml.\nChanges in deploy/runtime/k3d/volume are automatically reflected in PersistentVolume.\nUploading custom candump file to FeederCAN FeederCAN requires candump file. Pre-defined candump file is part of docker container release, however, if necessary, there is an option to upload the custom file by:\n Creating/updating candump file with with name candump in deploy/runtime/k3d/volume Recreating the feedercan pod: kubectl delete pods -l app=feedercan  More information about FeederCan can be found here\nNext steps  Setup and Explore Development Enviroment Deploy runtime services locally  ","categories":"","description":"","excerpt":"Besides local execution, another way of running the runtime components …","ref":"/velocitas-docs/docs/tutorials/vehicle-app-runtime/run_runtime_services_kubernetes/","tags":"","title":"Run runtime services in Kubernetes"},{"body":"Using tasks in Visual Studio Code Overview: If you are developing in Visual Studio Code, the runtime components (like Vehicle Data Broker or Vehicle Services) are available for local execution as Tasks, a feature of the Visual Studio Code. Additional information on tasks can be found here.\nQuick Start: Each component has a task that is defined in .vscode/tasks.json:\n Dapr (Local - Ensure Dapr): installs Dapr CLI and initializes Dapr if required Mosquitto (Local - Mosquitto): runs Mosquitto as a container (docker run) Vehicle Data Broker (Local - VehicleDataBroker): downloads and runs Vehicle Data Broker (Optional) Seat Service (Local - SeatService): downloads and runs Seat Service, an example Vehicle Service (Optional) Feeder Can (Local - FeederCan): downloads and runs FeederCAN  Run as Bundle: To orchestrate these tasks, a task called Start Vehicle App runtime is available. This task runs the other tasks in the correct order. You can run this task by clicking F1 and choose Tasks: Run task, then select Start Vehicle App runtime.\nTasks Management: Visual Studio Code offers various other commands concerning tasks like Start/Terminate/Restart/… You can access them by pressing F1 and typing task. A list with available task commands will appear.\nLogging: Running tasks appear in the Terminals View of Visual Studio Code. From there, you can see the logs of each running task.\nScripting: The tasks itself are executing scripts that are located in .vscode/scripts. These scripts download the specified version of the runtime components and execute them along with Dapr. The same mechanism can be used to register additional services or prerequisites by adding new task definitions in the tasks.json file.\nChange version of runtime services The version for the runtime services is defined in the file ./prerequisite_settings.json. If you want to update the version, change it within the file and re-run the runtime services by restarting the tasks or the script.\nUsing Vehicle Databroker CLI A CLI tool is provided for the interact with a running instance of the Vehicle Data Broker. It can be started by running the task run-vehicledatabroker-cli(by pressing F1, type Run Task followed by run-vehicledatabroker-cli). The Vehicle Data Broker needs to be running for you to be able to use the tool.\nIntegrating a new service into Visual Studio Code Task Integration of a new service can be done by duplicating one of the existing tasks.\n Create a new script based on template script .vscode/scripts/run-vehicledatabroker.sh In .vscode/tasks.json, duplicate section from task run-vehicledatabroker Correct names in a new code block Disclaimer: Problem Matcher defined in tasks.json is a feature of the Visual Studio Code Task, to ensure that the process runs in background Run task using [F1 -\u003e Tasks: Run Task -\u003e \u003cYour new task name\u003e] Task should be visible in Terminal section of Visual Studio Code  Task CodeBlock helper {  \"label\": \"\u003c__CHANGEIT: Task name__\u003e\",  \"type\": \"shell\",  \"command\": \"./.vscode/scripts/\u003c__CHANGEIT: Script Name.sh__\u003e --task\",  \"group\": \"none\",  \"presentation\": {  \"reveal\": \"always\",  \"panel\": \"dedicated\"  },  \"isBackground\": true,  \"problemMatcher\": {  \"pattern\": [  {  \"regexp\": \".\",  \"file\": 1,  \"location\": 2,  \"message\": 3  }  ],  \"background\": {  \"activeOnStart\": true,  \"beginsPattern\": \"^\u003c__CHANGEIT: Regex log from your app, decision to send process in background__\u003e\",  \"endsPattern\": \".\"  }  } }, Troubleshooting Problem description: When integrating new services into an existing dev environment, it is highly recommended to use the Visual Studio Code Task Feature. A new service can be easily started by calling it from bash script, however restarting the same service might lead to port conflicts (GRPC Port or APP port). That can be easily avoided by using the Visual Studio Code Task Feature.\nCodespaces If you are using Codespaces, remember that you are working on a remote agent. That’s why it could happen that the tasks are already running in the background. If that’s the case a new start of the tasks will fail, since the ports are already in use. In the Dapr-tab of the sidebar you can check if there are already tasks running. Another possibility to check if the processes are already running, is to check which ports are already open. Check the Ports-tab to view all open ports (if not already open, hit F1 and enter View: Toggle Ports).\nNext steps  Setup and Explore Development Enviroment Deploy runtime services in Kubernetes mode  ","categories":"","description":"","excerpt":"Using tasks in Visual Studio Code Overview: If you are developing in …","ref":"/velocitas-docs/docs/tutorials/vehicle-app-runtime/run_runtime_services_locally/","tags":"","title":"Run runtime services locally"},{"body":"","categories":"","description":"","excerpt":"","ref":"/velocitas-docs/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/velocitas-docs/tags/","tags":"","title":"Tags"},{"body":"  .mb-4 { margin-bottom: 0.5rem !important; } .mb-5 { margin-bottom: 2.0rem !important; }  Eclipse Velocitas Toolchain for creating containerized in-vehicle applications\nConcepts  Tutorials                  ","categories":"","description":"","excerpt":"  .mb-4 { margin-bottom: 0.5rem !important; } .mb-5 { margin-bottom: …","ref":"/velocitas-docs/","tags":"","title":"Velocitas"}]